---
title: "Week 2: Exploring Hosted LLMs"
format:
  revealjs:
    slide-number: true
    incremental: true
    center-title-slide: true
    theme: [default, ../../theme/digipen.scss]
    highlight-style: github
    width: 1050
    height: 700
    margin: 0.15
    mermaid:
      theme: neutral
logo: ../../theme/logos/DigiPen_RGB_Red.png
bibliography: references.bib
---

## Recap of Last Week's Lecture

- Explored the history of vector embeddings and tokenization
- Understood the transformer architecture at a high level
- Used our first transformer to translate language
- Covered a brief history of early generative transformers
- Setup and used Colab, and became familiar with the basics of notebooks and Python

## Lesson Objectives

- Understand the evolution and licensing of models from GPT-2 through to modern day
- Understand instruction-tuned models, how they work, and how to configure
- Setup and use OpenRouter for accessing hosted models
- Understand the OpenAI API specification, the request/response payload, parameters, streaming, and structured output
- Create and share a chatbot using a Gradio-based UI

# From GPT-2 to GPT-3.5

## From GPT-2 to GPT-3.5

```{mermaid}
timeline
    Feb 2019 : OpenAI releases GPT-2
             : 1.5B parameters
             : Initially withheld full model due to concerns about misuse
             : Demonstrates impressive text generation capabilities with minimal fine-tuning

    May 2020 : OpenAI releases GPT-3
             : 175B parameters
             : Demonstrates strong few-shot learning capabilities
             : Marks a significant leap in model capabilities and scale

    June 2020 : GPT-3 available through OpenAI API
              : Still a completion model, not instruction-tuned

    2021 : InstructGPT Development
          : Built on GPT-3 with RLHF fine-tuning
          : Trained to follow instructions and understand user intent
          : Key innovation enabling ChatGPT
    
    Jan 2021 : Anthropic Founded
             : Founded by Dario & Daniela Amodei with ~7 senior OpenAI employees
             : Dario led GPT-2/3 development and co-invented RLHF

    Nov 2022 : ChatGPT Launch
              : Built on GPT-3.5 using RLHF
              : 1M+ users in 5 days
              : Sparked widespread interest in generative AI
```

## Completion vs. Instruction-Tuned

- Completion Model just predicts the next token
  - Input prompt: `Mary had a little`
  - Max total tokens: `50`
  - Temperature: `0 - 1.0`
  - top_k: consider only the top k tokens in the response
  - top_p: Nucleus sampling (probability cut off - 0 and 1.0)
- Output
  - `Mary had a little lamb, its fleece was white as snow...`  (up to max tokens)

## Completion vs. Instruction-Tuned

- You can't really converse with it
- `What is the capital of France?` (max tokens = 50)
- `What is the capital of France? Paris. What is the capital of Spain? Madrid. What is the capital of`

## Instruction-Tuned Models

- Supervised Fine-Tuning
  - Large datasets of questions/answers, tasks/completions, demonstrating helpful assistant behavior
- RLHF (Reinforcement Learning from Human Feedback)
  - Human raters rank different model responses, training a reward model
- Chat Templates
  - Structured formats to distinguish speakers in a dialog: Typically system, user, and assistant

## Instruction-Tuned Models

{{< embed notebooks/instruction-tuned.ipynb#base-model echo=true >}}

## Instruction-Tuned Models

{{< embed notebooks/instruction-tuned.ipynb#it-model echo=true >}}

## What's a Chat Template?

- Instruction-tuned models are trained on conversations with specific formatting
- Each model family uses a different format (there is no universal standard)
- Wrong format will likely generate nonsense/garbage

## ChatML (GPT-3.5 and other models)

```
<|im_start|>system
You are a helpful assistant<|im_end|>
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
```

## Qwen

```
<|im_start|>system
You are a helpful assistant<|im_end|>
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
```

## Llama 3

```
<|begin_of_text|><|start_header_id|>user<|end_header_id|>
Hello<|eot_id|><|start_header_id|>assistant<|end_header_id|>
```

## Chat Templates in Practice

```
messages = [
    {"role": "system", "content": "You are a helpful assistant"},
    {"role": "user", "content": "Hello"},
    {"role": "assistant", "content": "Hi there!"},
    {"role": "user", "content": "What's 2+2?"}
]

formatted = tokenizer.apply_chat_template(
    messages, 
    tokenize=False,
    add_generation_prompt=True  # Adds the assistant prompt
)
```
  

# Looking Ahead to Next Week

## Looking Ahead to Next Week

- [This week's assignment!](https://simonguest.github.io/CS-394/src/02/assignment.html){.external target="_blank"}
- TBD

# References

## References
