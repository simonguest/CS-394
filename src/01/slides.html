<!DOCTYPE html>
<html lang="en"><head>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-597958c53c93a607afca12fd375c57ed.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.26">

  <title>CS-394 – Week 1: Foundations of Generative AI</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
      }
    pre.numberSource { margin-left: 3em;  padding-left: 4px; }
    div.sourceCode
      { color: #24292e;  }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #24292e; } /* Normal */
    code span.al { color: #ff5555; font-weight: bold; } /* Alert */
    code span.an { color: #6a737d; } /* Annotation */
    code span.at { color: #d73a49; } /* Attribute */
    code span.bn { color: #005cc5; } /* BaseN */
    code span.bu { color: #d73a49; } /* BuiltIn */
    code span.cf { color: #d73a49; } /* ControlFlow */
    code span.ch { color: #032f62; } /* Char */
    code span.cn { color: #005cc5; } /* Constant */
    code span.co { color: #6a737d; } /* Comment */
    code span.cv { color: #6a737d; } /* CommentVar */
    code span.do { color: #6a737d; } /* Documentation */
    code span.dt { color: #d73a49; } /* DataType */
    code span.dv { color: #005cc5; } /* DecVal */
    code span.er { color: #ff5555; text-decoration: underline; } /* Error */
    code span.ex { color: #d73a49; font-weight: bold; } /* Extension */
    code span.fl { color: #005cc5; } /* Float */
    code span.fu { color: #6f42c1; } /* Function */
    code span.im { color: #032f62; } /* Import */
    code span.in { color: #6a737d; } /* Information */
    code span.kw { color: #d73a49; } /* Keyword */
    code span.op { color: #24292e; } /* Operator */
    code span.ot { color: #6f42c1; } /* Other */
    code span.pp { color: #d73a49; } /* Preprocessor */
    code span.re { color: #6a737d; } /* RegionMarker */
    code span.sc { color: #005cc5; } /* SpecialChar */
    code span.ss { color: #032f62; } /* SpecialString */
    code span.st { color: #032f62; } /* String */
    code span.va { color: #e36209; } /* Variable */
    code span.vs { color: #032f62; } /* VerbatimString */
    code span.wa { color: #ff5555; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-eeafb82a00776dbd0312b01cd21cfa25.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <meta name="mermaid-theme" content="neutral">
  <script src="../../site_libs/quarto-diagram/mermaid.min.js"></script>
  <script src="../../site_libs/quarto-diagram/mermaid-init.js"></script>
  <link href="../../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Week 1: Foundations of Generative AI</h1>

<div class="quarto-title-authors">
</div>

</section>
<section id="lesson-objectives" class="slide level2">
<h2>Lesson Objectives</h2>
<ul>
<li class="fragment">Explore the history of vector embeddings and tokenization</li>
<li class="fragment">Understand the transformer architecture at a high level</li>
<li class="fragment">Use our first transformer to translate language</li>
<li class="fragment">Cover a brief history of early generative transformers</li>
<li class="fragment">Setup and use Colab, and become familiar with the basics of notebooks and Python (if you haven’t used them already)</li>
</ul>
</section>
<section>
<section id="lets-rewind-to-2013" class="title-slide slide level1 center">
<h1>Let’s Rewind To 2013…</h1>

</section>
<section id="rewind-to-2013" class="slide level2">
<h2>Rewind To 2013</h2>
<ul>
<li class="fragment">NLP (Natural Language Processing) was the thing!
<ul>
<li class="fragment">Sentiment analysis, named entity recognition, parsing, etc.</li>
</ul></li>
<li class="fragment">But, you had limited options…
<ul>
<li class="fragment">One-hot encoding</li>
<li class="fragment">Hand crafted features</li>
<li class="fragment">Neural language models</li>
</ul></li>
</ul>
</section>
<section id="word2vec-released" class="slide level2">
<h2>2013: Word2Vec Released</h2>
<ul>
<li class="fragment">Word2Vec introduced by Mikolov and colleagues at Google Research in two papers
<ul>
<li class="fragment">Skip-gram and Continuous Bag-of-Words (CBOW) <span class="citation" data-cites="mikolov2013efficient">(<a href="#/references-1" role="doc-biblioref" onclick="">Mikolov, Chen, et al. 2013</a>)</span></li>
<li class="fragment">Negative sampling and subsampling techniques <span class="citation" data-cites="mikolov2013distributed">(<a href="#/references-1" role="doc-biblioref" onclick="">Mikolov, Sutskever, et al. 2013</a>)</span></li>
</ul></li>
<li class="fragment">Paradigm shift from count-based methods
<ul>
<li class="fragment">Used Neural Networks (NNs) to predict words vs.&nbsp;large matrices</li>
</ul></li>
<li class="fragment">Foundation for modern NLP tasks</li>
</ul>
</section>
<section id="how-does-word2vec-work" class="slide level2">
<h2>How does Word2Vec Work?</h2>
<ul>
<li class="fragment">Word Embeddings are <strong>meaningful numerical representations</strong> of words
<ul>
<li class="fragment">Representations where words are encoded into multi-dimensional space</li>
<li class="fragment">Large number of dimensions (200-500 is typical)</li>
<li class="fragment">Similar words have similar numbers</li>
</ul></li>
</ul>
</section>
<section id="how-does-word2vec-work-1" class="slide level2">
<h2>How does Word2Vec Work?</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/01/notebooks/word2vec.ipynb" data-notebook-title="Word2Vec" data-notebook-cellid="word-1">
<div id="word-1" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a></a>word <span class="op">=</span> <span class="st">"cat"</span></span>
<span id="cb1-2"><a></a>vector <span class="op">=</span> model[word]</span>
<span id="cb1-3"><a></a>vector[:<span class="dv">10</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>array([ 0.0123291 ,  0.20410156, -0.28515625,  0.21679688,  0.11816406,
        0.08300781,  0.04980469, -0.00952148,  0.22070312, -0.12597656],
      dtype=float32)</code></pre>
</div>
</div>
</div>
</section>
<section id="how-does-word2vec-work-2" class="slide level2">
<h2>How does Word2Vec Work?</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/01/notebooks/word2vec.ipynb" data-notebook-title="Word2Vec" data-notebook-cellid="word-2">
<div id="word-2" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a></a>word <span class="op">=</span> <span class="st">"dog"</span></span>
<span id="cb3-2"><a></a>vector <span class="op">=</span> model[word]</span>
<span id="cb3-3"><a></a>vector[:<span class="dv">10</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>array([ 0.05126953, -0.02233887, -0.17285156,  0.16113281, -0.08447266,
        0.05737305,  0.05859375, -0.08251953, -0.01538086, -0.06347656],
      dtype=float32)</code></pre>
</div>
</div>
</div>
</section>
<section id="how-does-word2vec-work-3" class="slide level2">
<h2>How does Word2Vec Work?</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/01/notebooks/word2vec.ipynb" data-notebook-title="Word2Vec" data-notebook-cellid="word-3">
<div id="word-3" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a></a>word <span class="op">=</span> <span class="st">"pizza"</span></span>
<span id="cb5-2"><a></a>vector <span class="op">=</span> model[word]</span>
<span id="cb5-3"><a></a>vector[:<span class="dv">10</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>array([-1.2597656e-01,  2.5390625e-02,  1.6699219e-01,  5.5078125e-01,
       -7.6660156e-02,  1.2890625e-01,  1.0253906e-01, -3.9482117e-04,
        1.2158203e-01,  4.3212891e-02], dtype=float32)</code></pre>
</div>
</div>
</div>
</section>
<section id="why-do-this" class="slide level2">
<h2>Why Do This?</h2>
<ul>
<li class="fragment">Mapping words to multi-dimensional vectors enables
<ul>
<li class="fragment">Test for similarity</li>
<li class="fragment">Compute similarity</li>
<li class="fragment">Perform vector arithmetic</li>
<li class="fragment">Explore sets of words through visualizations</li>
</ul></li>
</ul>
</section>
<section id="how-does-word2vec-work-4" class="slide level2">
<h2>How does Word2Vec Work?</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/01/notebooks/word2vec.ipynb" data-notebook-title="Word2Vec" data-notebook-cellid="similar-words">
<div id="similar-words" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a></a>find_similar_words(<span class="st">"cat"</span>)</span>
<span id="cb7-2"><a></a>find_similar_words(<span class="st">"dog"</span>)</span>
<span id="cb7-3"><a></a>find_similar_words(<span class="st">"pizza"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Words most similar to 'cat':
----------------------------------------
cats                 | similarity: 0.8099
dog                  | similarity: 0.7609
kitten               | similarity: 0.7465
feline               | similarity: 0.7326
beagle               | similarity: 0.7151
puppy                | similarity: 0.7075
pup                  | similarity: 0.6934
pet                  | similarity: 0.6892
felines              | similarity: 0.6756
chihuahua            | similarity: 0.6710

Words most similar to 'dog':
----------------------------------------
dogs                 | similarity: 0.8680
puppy                | similarity: 0.8106
pit_bull             | similarity: 0.7804
pooch                | similarity: 0.7627
cat                  | similarity: 0.7609
golden_retriever     | similarity: 0.7501
German_shepherd      | similarity: 0.7465
Rottweiler           | similarity: 0.7438
beagle               | similarity: 0.7419
pup                  | similarity: 0.7407

Words most similar to 'pizza':
----------------------------------------
pizzas               | similarity: 0.7863
Domino_pizza         | similarity: 0.7343
Pizza                | similarity: 0.6988
pepperoni_pizza      | similarity: 0.6903
sandwich             | similarity: 0.6840
burger               | similarity: 0.6570
sandwiches           | similarity: 0.6495
takeout_pizza        | similarity: 0.6492
gourmet_pizza        | similarity: 0.6401
meatball_sandwich    | similarity: 0.6377</code></pre>
</div>
</div>
</div>
</section>
<section id="how-does-word2vec-work-5" class="slide level2">
<h2>How does Word2Vec Work?</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/01/notebooks/word2vec.ipynb" data-notebook-title="Word2Vec" data-notebook-cellid="compute-similarity">
<div id="compute-similarity" class="cell" data-execution_count="21">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a></a>compute_similarity(<span class="st">'cat'</span>, <span class="st">'dog'</span>)</span>
<span id="cb9-2"><a></a>compute_similarity(<span class="st">'cat'</span>, <span class="st">'kitten'</span>)</span>
<span id="cb9-3"><a></a>compute_similarity(<span class="st">'cat'</span>, <span class="st">'car'</span>)</span>
<span id="cb9-4"><a></a>compute_similarity(<span class="st">'doctor'</span>, <span class="st">'hospital'</span>)</span>
<span id="cb9-5"><a></a>compute_similarity(<span class="st">'king'</span>, <span class="st">'queen'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Similarity between 'cat' and 'dog': 0.7609
Similarity between 'cat' and 'kitten': 0.7465
Similarity between 'cat' and 'car': 0.2153
Similarity between 'doctor' and 'hospital': 0.5143
Similarity between 'king' and 'queen': 0.6511</code></pre>
</div>
</div>
</div>
</section>
<section id="how-does-word2vec-work-6" class="slide level2">
<h2>How does Word2Vec Work?</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/01/notebooks/word2vec.ipynb" data-notebook-title="Word2Vec" data-notebook-cellid="vector-arithmetic">
<div id="vector-arithmetic" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a></a>vector_arithmetic([<span class="st">'king'</span>, <span class="st">'woman'</span>], [<span class="st">'man'</span>])</span>
<span id="cb11-2"><a></a>vector_arithmetic([<span class="st">'Paris'</span>, <span class="st">'Italy'</span>], [<span class="st">'France'</span>])</span>
<span id="cb11-3"><a></a>vector_arithmetic([<span class="st">'walking'</span>, <span class="st">'swim'</span>], [<span class="st">'walk'</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
king + woman - man:
--------------------------------------------------
queen                | similarity: 0.7118
monarch              | similarity: 0.6190
princess             | similarity: 0.5902
crown_prince         | similarity: 0.5499
prince               | similarity: 0.5377

Paris + Italy - France:
--------------------------------------------------
Milan                | similarity: 0.7222
Rome                 | similarity: 0.7028
Palermo_Sicily       | similarity: 0.5968
Italian              | similarity: 0.5911
Tuscany              | similarity: 0.5633

walking + swim - walk:
--------------------------------------------------
swimming             | similarity: 0.8246
swam                 | similarity: 0.6807
swims                | similarity: 0.6538
swimmers             | similarity: 0.6495
paddling             | similarity: 0.6424</code></pre>
</div>
</div>
</div>
</section>
<section id="how-does-word2vec-work-7" class="slide level2">
<h2>How does Word2Vec Work?</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/01/notebooks/word2vec.ipynb" data-notebook-title="Word2Vec" data-notebook-cellid="2d-visualization">
<div id="2d-visualization" class="cell" data-execution_count="18">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="slides_files/figure-revealjs/notebooks-word2vec-cell-13-output-1.png"></p>
</figure>
</div>
</div>
</div>
</div>
</section></section>
<section id="lets-run-some-code" class="title-slide slide level1 center">
<h1>Let’s Run Some Code!</h1>

</section>

<section>
<section id="introducing-notebooks" class="title-slide slide level1 center">
<h1>Introducing Notebooks</h1>

</section>
<section id="what-is-a-notebook" class="slide level2">
<h2>What is a Notebook?</h2>
<ul>
<li class="fragment">An <strong>interactive document</strong> that combines:
<ul>
<li class="fragment">Live code that can be executed</li>
<li class="fragment">Rich text explanations (markdown)</li>
<li class="fragment">Visualizations and outputs</li>
</ul></li>
<li class="fragment">Think of it as a <strong>computational narrative</strong>
<ul>
<li class="fragment">Tell a story with code, data, and explanations</li>
</ul></li>
<li class="fragment">Originally designed for data science and research</li>
<li class="fragment">Also used for learning, experimenting, and sharing results</li>
</ul>
</section>
<section id="a-brief-history-of-notebooks" class="slide level2">
<h2>A Brief History of Notebooks</h2>
<ul>
<li class="fragment"><strong>2011</strong>: IPython Notebook project begins
<ul>
<li class="fragment">Interactive Python shell → web-based notebook</li>
</ul></li>
<li class="fragment"><strong>2014</strong>: Renamed to <strong>Jupyter</strong> (Julia, Python, R)
<ul>
<li class="fragment">Now supports 40+ programming languages</li>
<li class="fragment">Python is most popular by far</li>
</ul></li>
<li class="fragment"><strong>2017</strong>: Google launches <strong>Colab</strong>
<ul>
<li class="fragment">Free cloud-based Jupyter notebooks</li>
<li class="fragment">Free access to GPUs and TPUs</li>
</ul></li>
<li class="fragment"><strong>Today</strong>: Industry standard for ML/AI development</li>
</ul>
</section>
<section id="anatomy-of-a-python-notebook" class="slide level2">
<h2>Anatomy of a Python Notebook</h2>
<ul>
<li class="fragment"><strong>Format</strong>: Extension is .ipynb
<ul>
<li class="fragment">JSON format, using Jupyter Document Schema</li>
</ul></li>
<li class="fragment"><strong>Cells</strong>: Building blocks of notebooks
<ul>
<li class="fragment"><strong>Code cells</strong>: Executable Python code</li>
<li class="fragment"><strong>Markdown cells</strong>: Text, headings, images, equations</li>
</ul></li>
<li class="fragment"><strong>Kernel</strong>: The computational engine running your code
<ul>
<li class="fragment">Maintains state between cell executions</li>
</ul></li>
<li class="fragment"><strong>Outputs</strong>: Results appear directly below code cells
<ul>
<li class="fragment">Text, tables, plots, interactive widgets</li>
</ul></li>
</ul>
</section>
<section id="how-to-run-notebooks" class="slide level2">
<h2>How to Run Notebooks</h2>
<ul>
<li class="fragment"><strong>Jupyter Notebook Server</strong> (Classic approach)
<ul>
<li class="fragment">Web interface on localhost</li>
</ul></li>
<li class="fragment"><strong>VS Code</strong> (Local development)
<ul>
<li class="fragment">Jupyter extension for VS Code</li>
<li class="fragment">Run on your own machine</li>
</ul></li>
<li class="fragment"><strong>Google Colab</strong> (Recommended)
<ul>
<li class="fragment">Browser-based, no installation needed</li>
<li class="fragment">Free(-ish) GPU access</li>
<li class="fragment">Can also access local GPU</li>
</ul></li>
</ul>
</section>
<section id="advantages-of-google-colab" class="slide level2">
<h2>Advantages of Google Colab</h2>
<ul>
<li class="fragment">Access to GPUs and TPUs for AI-based tasks
<ul>
<li class="fragment">e.g., A100 and H100 with 40Gb/80Gb VRAM</li>
</ul></li>
<li class="fragment">Model downloaded between cloud vendors
<ul>
<li class="fragment">vs.&nbsp;downloading large models via the DigiPen network</li>
</ul></li>
<li class="fragment">Many libraries pre-installed</li>
<li class="fragment">Easy to share notebooks with others</li>
<li class="fragment">Generous (free) GPU limits for students!</li>
</ul>
</section></section>
<section id="demo" class="title-slide slide level1 center">
<h1>Demo</h1>
<p>Hello World and Word2Vec notebooks in <strong>Colab</strong>, <strong>VS Code</strong>, and <strong>Local Jupyter server</strong></p>
</section>

<section>
<section id="hands-on" class="title-slide slide level1 center">
<h1>Hands-On</h1>
<p>Setup Colab, get the two notebooks up and running (hello-world, word2vec)</p>
</section>
<section id="challenges-with-word-embeddings" class="slide level2">
<h2>Challenges with Word Embeddings</h2>
<ul>
<li class="fragment">Large vocabularies
<ul>
<li class="fragment">100K+ words</li>
<li class="fragment">And not particularly friendly to non-English vocabularies</li>
</ul></li>
<li class="fragment">Little representation between certain words
<ul>
<li class="fragment">“Run” and “Running” should be related</li>
</ul></li>
<li class="fragment">Lack of context
<ul>
<li class="fragment">Embedding for the word “bank” is the same, regardless of context</li>
<li class="fragment"><strong>River bank</strong> != <strong>Savings bank</strong></li>
</ul></li>
</ul>
</section>
<section id="challenges-with-word-embeddings-1" class="slide level2">
<h2>Challenges with Word Embeddings</h2>
<ul>
<li class="fragment">Some researchers tried character-level models
<ul>
<li class="fragment">Small vocabulary (26 letters + puntuation for English)</li>
<li class="fragment">But very long sequences</li>
<li class="fragment">And hard to extra meaning</li>
</ul></li>
</ul>
</section>
<section id="byte-pair-encoding-bpe" class="slide level2">
<h2>2016: Byte Pair Encoding (BPE)</h2>
<ul>
<li class="fragment">Originally developed in 1994 as a simple compression algorithm <span class="citation" data-cites="gage1994new">(<a href="#/references-1" role="doc-biblioref" onclick="">Gage 1994</a>)</span>
<ul>
<li class="fragment">Frequent pairs of adjacent bytes represented as a single byte</li>
</ul></li>
<li class="fragment">In 2016, adapted to neural machine translation <span class="citation" data-cites="sennrich-etal-2016-neural">(<a href="#/references-1" role="doc-biblioref" onclick="">Sennrich, Haddow, and Birch 2016</a>)</span>
<ul>
<li class="fragment">Applied BPE to break words into subword units for better handling of rare words</li>
</ul></li>
</ul>
</section>
<section id="byte-pair-encoding-bpe-1" class="slide level2">
<h2>2016: Byte Pair Encoding (BPE)</h2>
<ul>
<li class="fragment">Breaks words into frequent subword units (a.k.a. <strong>tokens</strong>)
<ul>
<li class="fragment">“unbelievable” → <strong>[“un”, “believ”, “able”]</strong></li>
</ul></li>
<li class="fragment">Balance between word level (large vocab) and character level (long sequences)
<ul>
<li class="fragment">Supports related words: <strong>[“Run”]</strong> and <strong>[“Run”, “ning”]</strong></li>
<li class="fragment">Supports unknown words</li>
<li class="fragment">30-50K tokens vs.&nbsp;100K</li>
<li class="fragment">Also works well for non-English languages</li>
</ul></li>
</ul>
</section>
<section id="search-for-context" class="slide level2">
<h2>Search for Context</h2>
<ul>
<li class="fragment">BPE provided efficiency and representation between words</li>
<li class="fragment">But still didn’t solve context
<ul>
<li class="fragment">e.g., the <strong>River bank</strong> != <strong>Savings bank</strong> problem</li>
</ul></li>
<li class="fragment">Researchers working on “attention tasks” using Recurrent Neural Networks (RNNs)
<ul>
<li class="fragment">Bahdanau et al.&nbsp;introduce attention for translation <span class="citation" data-cites="bahdanau2015neural">(<a href="#/references-1" role="doc-biblioref" onclick="">Bahdanau, Cho, and Bengio 2015</a>)</span></li>
<li class="fragment">Showed that focusing on relevant parts of input improved translation quality</li>
</ul></li>
</ul>
</section>
<section id="attention-is-all-you-need" class="slide level2">
<h2>2017: “Attention is all you need”</h2>
<ul>
<li class="fragment">Google researchers publish “Attention is all you need” <span class="citation" data-cites="vaswani2017attention">(<a href="#/references-1" role="doc-biblioref" onclick="">Vaswani et al. 2017</a>)</span>
<ul>
<li class="fragment">Introduced the <strong>Transformer</strong> a novel Neural Network (NN) architecture, eliminating the need for RNNs for sequence-to-sequence models</li>
<li class="fragment">Used BPE tokenization, and creates contextual embeddings during training process</li>
<li class="fragment">Attention mechanism allows the model to weigh the importance of words in a sequence</li>
<li class="fragment">Achieved State Of The Art (SOTA) performance on language translation, while also being faster to train</li>
</ul></li>
</ul>
</section></section>
<section>
<section id="introducing-the-transformer" class="title-slide slide level1 center">
<h1>Introducing the Transformer</h1>

</section>
<section id="introducing-the-transformer-1" class="slide level2">
<h2>Introducing the Transformer</h2>
<div class="cell" data-reveal="true" data-fig-height="100%" data-file="diagrams/transformer-1.mmd" data-layout-align="default">
<div class="cell-output-display">
<div id="transformer-1">
<div>
<pre class="mermaid mermaid-js" data-label="transformer-1">graph LR
    Input["Input: 'Bonjour, comment allez-vous?'"]
    Transformer[Transformer]
    Output["Output: 'Hello, how are you?'"]
    
    Input --&gt; Tokenize --&gt; Transformer --&gt; Decode --&gt; Output</pre>
</div>
</div>
</div>
</div>
</section>
<section id="example" class="slide level2">
<h2>Example</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/01/notebooks/translation-transformer.ipynb" data-notebook-title="Translation Transformer" data-notebook-cellid="load-model">
<div id="load-model" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a></a><span class="co"># @title Load Model</span></span>
<span id="cb13-2"><a></a></span>
<span id="cb13-3"><a></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer, AutoModelForSeq2SeqLM</span>
<span id="cb13-4"><a></a></span>
<span id="cb13-5"><a></a>model_name <span class="op">=</span> <span class="st">"Helsinki-NLP/opus-mt-fr-en"</span></span>
<span id="cb13-6"><a></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb13-7"><a></a>model <span class="op">=</span> AutoModelForSeq2SeqLM.from_pretrained(model_name)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"554eae15412f407392def18a94e2cdf3","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"980e33c84ae642ee80074c3d4d7f19d5","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"39a1afb6c66a4bdb9618b8d7fbebc31b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"247f590ae2df430782f38916467e2989","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5c46def7aa704024a5d1c6d1fef58711","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
</div>
</section>
<section id="example-1" class="slide level2">
<h2>Example</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/01/notebooks/translation-transformer.ipynb" data-notebook-title="Translation Transformer" data-notebook-cellid="tokenize">
<div id="tokenize" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a></a><span class="co"># @title Tokenize</span></span>
<span id="cb14-2"><a></a></span>
<span id="cb14-3"><a></a>french_text <span class="op">=</span> <span class="st">"Bonjour, comment allez-vous?"</span></span>
<span id="cb14-4"><a></a>input_ids <span class="op">=</span> tokenizer.encode(french_text, return_tensors<span class="op">=</span><span class="st">"pt"</span>)</span>
<span id="cb14-5"><a></a><span class="bu">print</span>(input_ids[<span class="dv">0</span>])</span>
<span id="cb14-6"><a></a><span class="bu">print</span>(<span class="st">"Tokens:"</span>, tokenizer.convert_ids_to_tokens(input_ids[<span class="dv">0</span>]))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([8703,    2, 1027, 5682,   21,  682,   54,    0])
Tokens: ['▁Bonjour', ',', '▁comment', '▁allez', '-', 'vous', '?', '&lt;/s&gt;']</code></pre>
</div>
</div>
</div>
</section>
<section id="example-2" class="slide level2">
<h2>Example</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/01/notebooks/translation-transformer.ipynb" data-notebook-title="Translation Transformer" data-notebook-cellid="transformer">
<div id="transformer" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a></a><span class="co"># @title Run through transformer</span></span>
<span id="cb16-2"><a></a></span>
<span id="cb16-3"><a></a>output_ids <span class="op">=</span> model.generate(input_ids)</span>
<span id="cb16-4"><a></a><span class="bu">print</span>(output_ids)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[59513, 10537,     2,   541,    52,    55,    54,     0]])</code></pre>
</div>
</div>
</div>
</section>
<section id="example-3" class="slide level2">
<h2>Example</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/01/notebooks/translation-transformer.ipynb" data-notebook-title="Translation Transformer" data-notebook-cellid="decode">
<div id="decode" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a></a><span class="co"># @title Decode back to tokens to complete the translation</span></span>
<span id="cb18-2"><a></a></span>
<span id="cb18-3"><a></a>english_text <span class="op">=</span> tokenizer.decode(output_ids[<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-4"><a></a><span class="bu">print</span>(<span class="st">"Translation:"</span>, english_text)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Translation: Hello, how are you?</code></pre>
</div>
</div>
</div>
</section>
<section id="introducing-the-transformer-2" class="slide level2">
<h2>Introducing the Transformer</h2>
<div class="cell" data-reveal="true" data-fig-height="100%" data-file="diagrams/transformer-1.mmd" data-layout-align="default">
<div class="cell-output-display">
<div id="transformer-1">
<div>
<pre class="mermaid mermaid-js" data-label="transformer-1">graph LR
    Input["Input: 'Bonjour, comment allez-vous?'"]
    Transformer[Transformer]
    Output["Output: 'Hello, how are you?'"]
    
    Input --&gt; Tokenize --&gt; Transformer --&gt; Decode --&gt; Output</pre>
</div>
</div>
</div>
</div>
</section>
<section id="introducing-the-transformer-3" class="slide level2">
<h2>Introducing the Transformer</h2>
<div class="cell" data-reveal="true" data-fig-height="100%" data-file="diagrams/transformer-2.mmd" data-layout-align="default">
<div class="cell-output-display">
<div id="transformer-2">
<div>
<pre class="mermaid mermaid-js" data-label="transformer-2">graph LR
    Input["Input: 'Bonjour, comment allez-vous?'"]
    
    subgraph Transformer
        Encoder[Encoder]
        Decoder[Decoder]
        Encoder --&gt; Decoder
    end
    
    Output["Output: 'Hello, how are you?'"]
    
    Input --&gt; Tokenize --&gt; Encoder
    Decoder --&gt; Decode --&gt; Output</pre>
</div>
</div>
</div>
</div>
</section>
<section id="introducing-the-transformer-4" class="slide level2">
<h2>Introducing the Transformer</h2>
<div class="cell" data-reveal="true" data-fig-height="100%" data-file="diagrams/transformer-3.mmd" data-layout-align="default">
<div class="cell-output-display">
<div id="transformer-3">
<div>
<pre class="mermaid mermaid-js" data-label="transformer-3">graph LR
    Input["Input: 'Bonjour, comment allez-vous?'"]
    
    subgraph Transformer
        direction LR
        subgraph "Encoder Stack (N layers)"
            E[Encoder&lt;br/&gt;Layers&lt;br/&gt;1...N]
        end
        
        subgraph "Decoder Stack (N layers)"
            D[Decoder&lt;br/&gt;Layers&lt;br/&gt;1...N]
        end
        
        E -.-&gt;|Context| D
    end
    
    Output["Output: 'Hello, how are you?'"]
    
    Input --&gt; Tokenize --&gt; E
    D --&gt; Decode --&gt; Output</pre>
</div>
</div>
</div>
</div>
</section>
<section id="how-does-the-encoderdecoder-work" class="slide level2">
<h2>How Does the Encoder/Decoder Work?</h2>
<p><code>output_ids = model.generate(input_ids)</code></p>
<ul>
<li class="fragment">Takes input ids, runs through encoder
<ul>
<li class="fragment">Generates contextual vectors using self attention across input tokens</li>
</ul></li>
<li class="fragment">Runs the decoder iteratively to generate <strong>one token at a time</strong>
<ul>
<li class="fragment">Uses self attention on previously generated tokens</li>
<li class="fragment">Uses cross-attention to attend to encoder output</li>
</ul></li>
<li class="fragment">Continues until it generates an end-of-sequence token or hits max length</li>
</ul>
</section>
<section id="introducing-the-transformer-5" class="slide level2">
<h2>Introducing the Transformer</h2>
<div class="cell" data-reveal="true" data-fig-height="100%" data-file="diagrams/transformer-4.mmd" data-layout-align="default">
<div class="cell-output-display">
<div id="transformer-4">
<div>
<pre class="mermaid mermaid-js" data-label="transformer-4">graph LR
    Input["Input: 'Bonjour, comment allez-vous?'"]
    
    subgraph Transformer
        direction TB
        
        subgraph "Encoder Layer"
            direction TB
            E_SelfAttn[Multi-Head&lt;br/&gt;Self-Attention]
            E_AddNorm1[Add &amp; Norm]
            E_FFN[Feed-Forward&lt;br/&gt;Network]
            E_AddNorm2[Add &amp; Norm]
            
            E_SelfAttn --&gt; E_AddNorm1 --&gt; E_FFN --&gt; E_AddNorm2
        end
        
        subgraph "Decoder Layer"
            direction TB
            D_SelfAttn[Masked Multi-Head&lt;br/&gt;Self-Attention]
            D_AddNorm1[Add &amp; Norm]
            D_CrossAttn[Multi-Head&lt;br/&gt;Cross-Attention]
            D_AddNorm2[Add &amp; Norm]
            D_FFN[Feed-Forward&lt;br/&gt;Network]
            D_AddNorm3[Add &amp; Norm]
            
            D_SelfAttn --&gt; D_AddNorm1 --&gt; D_CrossAttn --&gt; D_AddNorm2 --&gt; D_FFN --&gt; D_AddNorm3
        end
        
        E_AddNorm2 -.-&gt;|Encoder&lt;br/&gt;Output| D_CrossAttn
    end
    
    Output["Output: 'Hello, how are you?'"]
    
    Input --&gt; E_SelfAttn
    D_AddNorm3 --&gt; Output</pre>
</div>
</div>
</div>
</div>
</section></section>
<section id="demo-1" class="title-slide slide level1 center">
<h1>Demo</h1>
<p>Translation Transformer in Colab</p>
</section>

<section id="hands-on-1" class="title-slide slide level1 center">
<h1>Hands-On</h1>
<p>Experiment with your own phrases in the translation-transformer.ipynb notebook</p>
</section>

<section>
<section id="origin-of-gpt" class="title-slide slide level1 center">
<h1>2018: Origin of “GPT”</h1>

</section>
<section id="origin-of-gpt-1" class="slide level2">
<h2>2018: Origin of “GPT”</h2>
<ul>
<li class="fragment"><strong>G</strong>enerative <strong>P</strong>re-trained <strong>T</strong>ransformer</li>
<li class="fragment">Name coined by OpenAI researchers in “Improving Language Understanding by Generative Pre-Training” <span class="citation" data-cites="radford2018improving">(<a href="#/references-1" role="doc-biblioref" onclick="">Radford et al. 2018</a>)</span></li>
</ul>
</section>
<section id="what-is-a-gpt" class="slide level2">
<h2>What is a GPT?</h2>
<ul>
<li class="fragment">“Decoder-only” architecture
<ul>
<li class="fragment">Self attention is causal/masked - tokens can only attend to previous tokens, not future ones</li>
</ul></li>
<li class="fragment">Pre-training objective: Next token prediction
<ul>
<li class="fragment">Trained on a massive text corpora</li>
<li class="fragment">Learns grammar, facts, reasoning patterns just from this objective</li>
</ul></li>
</ul>
</section>
<section id="what-is-a-gpt-1" class="slide level2">
<h2>What is a GPT?</h2>
<ul>
<li class="fragment">Autoregressive generation
<ul>
<li class="fragment">Generates one token at a time, feeding back each output as input</li>
<li class="fragment">Temperature and sampling strategies</li>
<li class="fragment">Same prompt can produce different outputs</li>
</ul></li>
<li class="fragment">Context window
<ul>
<li class="fragment">Fixed maximum length (2048 for GPT-2)</li>
<li class="fragment">Everything must fit within this window during generation</li>
<li class="fragment">Introduced the concept of “context” vs.&nbsp;“knowledge” (prompt vs.&nbsp;training)</li>
</ul></li>
</ul>
</section>
<section id="gpt-2" class="slide level2">
<h2>GPT-2</h2>
<ul>
<li class="fragment">Released in 2019 by OpenAI
<ul>
<li class="fragment">Initially, only 117M param model released in Feb 2019 due to safety concerns</li>
<li class="fragment">Staged releases throughout the year, 1.5B in Nov 2019</li>
</ul></li>
<li class="fragment">Trained on WebText, 8 million web pages/40GB of text</li>
<li class="fragment">Zero-shot task performance
<ul>
<li class="fragment">Did well on translation, summarization, and question answering without task-specific training</li>
</ul></li>
</ul>
</section>
<section id="example-4" class="slide level2">
<h2>Example</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/01/notebooks/GPT-2.ipynb" data-notebook-title="Pre-trained GPT-2 Notebook" data-notebook-cellid="load-model">
<div id="load-model" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a></a><span class="im">from</span> transformers <span class="im">import</span> GPT2LMHeadModel, GPT2Tokenizer</span>
<span id="cb20-2"><a></a></span>
<span id="cb20-3"><a></a><span class="co"># Load pre-trained GPT-2 model and tokenizer</span></span>
<span id="cb20-4"><a></a>tokenizer <span class="op">=</span> GPT2Tokenizer.from_pretrained(<span class="st">"gpt2"</span>)</span>
<span id="cb20-5"><a></a>model <span class="op">=</span> GPT2LMHeadModel.from_pretrained(<span class="st">"gpt2"</span>)</span>
<span id="cb20-6"><a></a></span>
<span id="cb20-7"><a></a><span class="co"># Set pad token</span></span>
<span id="cb20-8"><a></a>tokenizer.pad_token <span class="op">=</span> tokenizer.eos_token</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</section>
<section id="example-5" class="slide level2">
<h2>Example</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/01/notebooks/GPT-2.ipynb" data-notebook-title="Pre-trained GPT-2 Notebook" data-notebook-cellid="autocomplete">
<div id="autocomplete" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a></a><span class="im">import</span> torch</span>
<span id="cb21-2"><a></a></span>
<span id="cb21-3"><a></a><span class="kw">def</span> autocomplete(prompt, max_length<span class="op">=</span><span class="dv">50</span>, temperature<span class="op">=</span><span class="fl">0.7</span>, top_k<span class="op">=</span><span class="dv">50</span>, top_p<span class="op">=</span><span class="fl">0.9</span>):</span>
<span id="cb21-4"><a></a>    <span class="co"># Encode the prompt with attention mask</span></span>
<span id="cb21-5"><a></a>    inputs <span class="op">=</span> tokenizer(prompt, return_tensors<span class="op">=</span><span class="st">"pt"</span>)</span>
<span id="cb21-6"><a></a>    </span>
<span id="cb21-7"><a></a>    <span class="co"># Generate continuation</span></span>
<span id="cb21-8"><a></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb21-9"><a></a>        output <span class="op">=</span> model.generate(</span>
<span id="cb21-10"><a></a>            inputs[<span class="st">'input_ids'</span>],</span>
<span id="cb21-11"><a></a>            attention_mask<span class="op">=</span>inputs[<span class="st">'attention_mask'</span>],</span>
<span id="cb21-12"><a></a>            max_length<span class="op">=</span>max_length,</span>
<span id="cb21-13"><a></a>            temperature<span class="op">=</span>temperature,</span>
<span id="cb21-14"><a></a>            top_k<span class="op">=</span>top_k,</span>
<span id="cb21-15"><a></a>            top_p<span class="op">=</span>top_p,</span>
<span id="cb21-16"><a></a>            do_sample<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb21-17"><a></a>            pad_token_id<span class="op">=</span>tokenizer.eos_token_id</span>
<span id="cb21-18"><a></a>        )</span>
<span id="cb21-19"><a></a>    </span>
<span id="cb21-20"><a></a>    <span class="co"># Decode and return the generated text</span></span>
<span id="cb21-21"><a></a>    generated_text <span class="op">=</span> tokenizer.decode(output[<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-22"><a></a>    <span class="cf">return</span> generated_text</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</section>
<section id="example-6" class="slide level2">
<h2>Example</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/01/notebooks/GPT-2.ipynb" data-notebook-title="Pre-trained GPT-2 Notebook" data-notebook-cellid="prompts">
<div id="prompts" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="7decbea9-1b4b-4208-a441-a65f9be042d2" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a></a>prompt <span class="op">=</span> <span class="st">"Mary had a little lamb"</span></span>
<span id="cb22-2"><a></a>completion <span class="op">=</span> autocomplete(prompt, max_length<span class="op">=</span><span class="dv">80</span>)</span>
<span id="cb22-3"><a></a><span class="bu">print</span>(completion)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mary had a little lamb, and the young woman asked her for a little lamb, and they gave it to her.

"Oh, my child, it is good to have a little lamb," said he, "but it is not to be bought, for it is hard to make, and it is much more difficult to make.

"When you have a little lamb, it</code></pre>
</div>
</div>
</div>
</section></section>
<section id="demo-2" class="title-slide slide level1 center">
<h1>Demo</h1>
<p>GPT-2 notebook in Colab</p>
</section>

<section id="hands-on-2" class="title-slide slide level1 center">
<h1>Hands-On</h1>
<p>Experiment with your own phrases in the GPT-2.ipynb notebook</p>
</section>

<section>
<section id="references" class="title-slide slide level1 center">
<h1>References</h1>

</section>
<section id="references-1" class="slide level2 smaller scrollable">
<h2>References</h2>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-bahdanau2015neural" class="csl-entry" role="listitem">
Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. 2015. <span>“Neural Machine Translation by Jointly Learning to Align and Translate.”</span> In <em>International Conference on Learning Representations</em>. <a href="https://arxiv.org/abs/1409.0473">https://arxiv.org/abs/1409.0473</a>.
</div>
<div id="ref-gage1994new" class="csl-entry" role="listitem">
Gage, Philip. 1994. <span>“A New Algorithm for Data Compression.”</span> <em>The C Users Journal</em> 12 (2): 23–38.
</div>
<div id="ref-mikolov2013efficient" class="csl-entry" role="listitem">
Mikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. <span>“Efficient Estimation of Word Representations in Vector Space.”</span> In <em>International Conference on Learning Representations</em>. <a href="https://arxiv.org/abs/1301.3781">https://arxiv.org/abs/1301.3781</a>.
</div>
<div id="ref-mikolov2013distributed" class="csl-entry" role="listitem">
Mikolov, Tomas, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. <span>“Distributed Representations of Words and Phrases and Their Compositionality.”</span> In <em>Advances in Neural Information Processing Systems</em>, 3111–19. <a href="https://arxiv.org/abs/1310.4546">https://arxiv.org/abs/1310.4546</a>.
</div>
<div id="ref-radford2018improving" class="csl-entry" role="listitem">
Radford, Alec, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 2018. <span>“Improving Language Understanding by Generative Pre-Training.”</span> <a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf</a>.
</div>
<div id="ref-sennrich-etal-2016-neural" class="csl-entry" role="listitem">
Sennrich, Rico, Barry Haddow, and Alexandra Birch. 2016. <span>“Neural Machine Translation of Rare Words with Subword Units.”</span> In <em>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, 1715–25. Berlin, Germany: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/P16-1162">https://doi.org/10.18653/v1/P16-1162</a>.
</div>
<div id="ref-vaswani2017attention" class="csl-entry" role="listitem">
Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. <span>“Attention Is All You Need.”</span> In <em>Advances in Neural Information Processing Systems</em>. Vol. 30.
</div>
</div>
</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="../../theme/logos/DigiPen_RGB_Red.png" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.15,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/simonguest\.github\.io\/CS-394\/");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>