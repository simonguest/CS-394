---
title: "Module 6: Increasing Model Accuracy (Part 1)"
format:
  revealjs:
    slide-number: true
    incremental: true
    center-title-slide: true
    theme: [default, ../../theme/digipen.scss]
    highlight-style: github
    width: 1050
    height: 700
    margin: 0.15
    mermaid:
      theme: neutral
logo: ../../theme/logos/DigiPen_RGB_Red.png
bibliography: references.bib
---

## Recap

- Understood the use cases, advantages/disadvantages for running models on local hardware - desktop, web, mobile
- Understood hardware requirements and architectures for model inference - e.g., CUDA vs. ONNX vs. MLX vs. WebGPU
- Explored how quantization works and understood techniques and formats for quantizing existing models
- Used llama.cpp to quantize and run an SLM on local hardware/gaming PC
- Integrated a quantized model within Unity/Unreal/WebAssembly

## Lesson Objectives

- Understand model training, dataset curation, what leads to hallucinations in models, how models are evaluated, and an overview of techniques to increase accuracy
- Explore use cases, advantages, and disadvantages of prompt engineering
- Introduce and implement RAG (Retrieval-Augmented Generation) to increase the accuracy of a limited SLM
- Start exploring how to fine-tune models using LoRA (Low Ranked Adaptation)
- Generate synthetic data for fine-tuning a 1B parameter model

# Hallucinations

## Hallucinations

- Models hallucinate!
  - Especially noticable on older and smaller models
  - Many hallucinations can be difficult to spot as they sound so plausible
  - Plausible sounding requests (i.e., asking about something that doesn't exist) often results in a hallucination

## Hallucinations

{{< embed notebooks/hallucinations.ipynb#setup-client echo=true outputs=false >}}

## Hallucinations: Citations

{{< embed notebooks/hallucinations.ipynb#hallucinate-1 echo=true outputs=false >}}

## Hallucinations: Citations

{{< embed notebooks/hallucinations.ipynb#hallucinate-1 echo=false >}}

## Hallucinations: Local Knowledge

{{< embed notebooks/hallucinations.ipynb#hallucinate-2 echo=true outputs=false >}}

## Hallucinations: Local Knowledge

{{< embed notebooks/hallucinations.ipynb#hallucinate-2 echo=false >}}

## Hallucinations: Summarization

{{< embed notebooks/hallucinations.ipynb#hallucinate-3 echo=true outputs=false >}}

## Hallucinations: Summarization

{{< embed notebooks/hallucinations.ipynb#hallucinate-3 echo=false >}}

## Why Do Models Hallucinate?

- A language model is not a database
  - It's a stochastic prediction machine
  - Models often don't know how to say "I don't know"
  - Instead, they are designed to come up with the most plausible continuation, not to retrieve verified facts
  - (Hallucination isn't a bug in the traditional sense)

## Why Do Models Hallucinate?

- Models are trained on a large corpora of Internet data
  - Data on the Internet is often uneven
  - Full of gaps
  - Often contradictory

## Why Do Models Hallucinate?

- Model Size vs. Training Set Size
  - Many of the latest models hold billions of parameters
  - But they are trained on trillions of tokens
  - Thus, they can't memorize everything and instead recognize patterns to recall information

# Model Accuracy

## Model Accuracy

- Intro to how models can be improved
  - Better prompt engineering
  - Reasoning/Chain of thought
  - Context Injection, leading to RAG - Retrieval Augmented Generation

## Prompt Engineering

- TBD
- Back to the three areas we mentioned in module 2
- Maybe look at the system prompts

## Prompt Engineering

- System Prompt best practices
  - **Be specific**: "You are a Python programming tutor who explains concepts using simple analogies and provides code examples."
  - **Define output**: "List no more than 3 suggestions. Always show your work step by step."
  - **Set boundaries**: "If you are asked questions outside coding, politely redirect the student back to the task."

## Reasoning

- TBD
- Reasoning and Chain of Thought as ways to increase accuracy

## Reasoning

- TBD
- Prompt engineering and reasoning helps guide the model to the type of output you want - but it doesn't solve the problem of getting the right answer
- Enter RAG

# Context Injection

## Context Injection

- A model's training data will only only answer so much
  - Training data has a cut-off: Your model won't know anything after that
  - Your model won't know if anything has changed since being trained
  - Function calling can help bridge this gap, but context injection is often simpler and more flexible

## Context Injection

- How it works
  - Take the user's prompt (e.g., "Who teaches CS-394?")
  - Do a database look-up to find relevant information (context)
  - Inject that context into the system prompt
  - Call the model with the modified system prompt

## Context Injection

- The injected information is called 'context', and adding it is called 'augmenting' the prompt
  - Hence the popular term, augmented generation
  - Two examples:
    - SQL-Augmented Generation
    - Retrieval-Augmented Generation

## SQL-Augmented Generation

{{< embed notebooks/sql-augmented.ipynb#call-without echo=true outputs=false >}}

## SQL-Augmented Generation

{{< embed notebooks/sql-augmented.ipynb#call-without echo=false >}}

## SQL-Augmented Generation

{{< embed notebooks/sql-augmented.ipynb#create-db echo=true outputs=false >}}

## SQL-Augmented Generation

{{< embed notebooks/sql-augmented.ipynb#build-context echo=true outputs=false >}}

## SQL-Augmented Generation

{{< embed notebooks/sql-augmented.ipynb#call-with echo=true outputs=false >}}

## SQL-Augmented Generation

{{< embed notebooks/sql-augmented.ipynb#call-with echo=false >}}

## SQL-Augmented Generation

- Good results, but...
  - Requires the course code to be in the user prompt, matched to a RegEx pattern
  - Will answer "Who teaches CS-394?" and "When is CS-394 held?"
  - Won't answer broader queries:
    - "What courses teach generative AI?"
    - "Which courses are on Friday afternoons?"
  - Could make a free-text search through the database...
  - But there's a better way...

## RAG: Retrieval-Augmented Generation

- Roots of RAG trace back to 1950s and 60s, when researchers were working with vector space models
- Term was coined in 2020 in "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks" by Patrick Lewis et. al (https://arxiv.org/pdf/2005.11401)
- “We definitely would have put more thought into the name had we known our work would become so widespread”

## How RAG Works

- Create "documents"
  - Strings of text - can be from existing db queries or scraped from PDFs
  - Generate embeddings (using a Sentence Transformer)
  - Store embeddings in a database
- User prompt is converted into an embedding
- Find the closest set of embeddings that match and inject into the system prompt

## Sidebar: Sentence Transformers

- In Module 1, we covered Word2Vec
  - Creating embeddings from words
- A sentence transformer creates embeddings from sentences
- Many models available (e.g., all-MiniLM-L6-v2, a 384-dim vector space)

## How RAG Works

{{< embed notebooks/rag.ipynb#create-db echo=true outputs=false >}}

## How RAG Works

{{< embed notebooks/rag.ipynb#build-context echo=true outputs=false >}}

## How RAG Works

{{< embed notebooks/rag.ipynb#call-with echo=true outputs=false >}}

## How RAG Works

- "Which courses teach about generative AI?"

## How RAG Works

{{< embed notebooks/rag.ipynb#call-with echo=false >}}

## How RAG Works

![](diagrams/rag.svg){.lightbox fig-align="center" width="600px"}

# Hands-on

Investigate sql-augmented.ipynb and rag.ipynb

Try different queries. Which work well on both?

Recreate the database with different data.

## RAG Databases

- Extensions
  - sqlite-vec: SQLite Extension (we've been using that!)
  - pgvector: PostgreSQL extension
- Libraries
  - FAISS (Meta): In-memory vector index vs. database. Very fast.

## RAG Databases

- Pinecone: Popular commercial managed/cloud option.
- Qdrant: Open-source dedicated db, written in Rust.
- Milvus: Open-source. Heavier to operate, but can exceed a billion embeddings.

## Beyond RAG

- While system prompting and RAG go so far, there are cases where you want the model to do something beyond
- Examples
- Fine-Tuning

# Evaluating Models

## Evaluating Models

- TBD
- Before we look at improving accuracy of models, should understand how models are evaluated
- How evaluations work, especially on non-multiple choice questions

## MMLU-Pro (Massive Multitask Language Understanding)

[https://huggingface.co/datasets/TIGER-Lab/MMLU-Pro](https://huggingface.co/datasets/TIGER-Lab/MMLU-Pro){.external target="_blank"}

- **What it tests:** 12K questions across 14 subject areas that cover STEM, humanities, social sciences, and professional domains. 
  - Multiple-choice questions (10 options) testing both factual knowledge and reasoning across elementary to professional levels.
- **History:** Original MMLU published in 2021 by Dan Hendrycks et al. 
  - MMLU-Pro created because models were plateauing on MMLU (hitting 85-90%+)
  - Pro released in June 2024 by the TIGER-AI-Lab team and accepted at NeurIPS 2024

## GPQA (Graduate-Level Google-Proof Q&A)

[https://huggingface.co/datasets/Idavidrein/gpqa](https://huggingface.co/datasets/Idavidrein/gpqa){.external target="_blank"}

- **What it tests:** Graduate/PhD-level scientific reasoning in biology, physics, and chemistry through multiple-choice questions
  - Require deep domain understanding, not just fact recall
  - Cannot be solved by web search (the "Google-proof" property)
  - Test genuine conceptual reasoning and problem-solving
- **History:**
  - Created Nov 2023 by David Rein et al. (includes researchers from NYU, Anthropic, and other institutions)

## SWE-Bench

[https://www.swebench.com/](https://www.swebench.com/){.external target="_blank"}

- **What it tests:** AI systems' ability to solve real-world software engineering tasks by resolving actual GitHub issues from popular open-source Python repositories
- **History:** Created: 2023 by Princeton NLP group (Carlos E. Jimenez et al.)
  - Original dataset was 2,294 GitHub issues from 12 popular Python repositories (Django, scikit-learn, Flask, Matplotlib, Requests, SymPy, pytest, Sphinx, etc.)
  - Three major variants: Lite, Verified, and Pro
  - Microsoft also publishes a "Live" version with monthly curated updates

## HLE (Humanity's Last Exam)

[https://huggingface.co/datasets/cais/hle](https://huggingface.co/datasets/cais/hle){.external target="_blank"}

- **What it tests:** 2,500 expert-level questions across dozens of subjects, including mathematics, humanities, and the natural sciences. 
  - HLE is developed globally by subject-matter experts and consists of multiple-choice and short-answer questions suitable for automated grading.
  - Require multimodal, multi-step reasoning rather than pattern matching or recall
  - Be "Google-proof" (can't be quickly answered by web search)
- **History:** Created in late 2024 by the Center for AI Safety (CAIS) and Scale AI
  - Led by: Dan Hendrycks (who also created MMLU and MATH benchmarks)

# Demo of Benchmarks

## Challenges with Eval Benchmarks

- TBD
- Speak about officially testing vs. self reporting
- Dataset contamination
- Link to HF's latest efforts to try to curb this
- Don't test creativity

# Fine-tuning

## Fine-tuning

- Prompt Engineering and Context Injection (RAG) can help improve the output and accuracy of models
- However, sometimes you need the model to have more consistency in its style, structure, or behavior

## Fine-tuning

- Fine-tuning is the process of taking a pre-trained model and continuing to train it on a smaller, task-specific dataset using curated examples
- This allows it to adapt its general capabilities toward a particular **style**, **structure** or **behavior** without learning from scratch

## Fine-tuning

- Examples
  - **Style:** Adopting a different voice at scale: Speak to students using "Hinglish" at a 5th grade level
  - **Structure**: Generating outputs in a precise format: Player movement instructions in a game, in JSON format
  - **Behavior**: Always refuse off-topic questions and redirect to the subject matter (guardrail)

## History of Fine-tuning

- 2010s: Fine-tuning became prevalent in computer vision (e.g., ImageNet-trained CNNs for medical)
- 2018: BERT demonstrated that a language model could be fine-tuned for sentiment, Q&A, and classification
- 2022: InstructGPT fine-tuning on human-curated instruction-response pairs
- Today: Very popular technique for adapting trained models to different use cases

## When To Pick What

- Prompt Engineering shapes how the model responds to input
- Context Injection (RAG) augments the context with data
- Fine-tuning reshapes the model itself
- (A combination of all three are often used together)

## Sidebar: Can We Train Models From Scratch?

- [NanoChat](https://github.com/karpathy/nanochat){.external target="_blank"} shows that it's possible
  - 60x faster and 652x cheaper than original GPT-2 in 2019
- But you may not have the data nor the GPU compute to build a capable model
  - Trained on [fineweb-edu](https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu){.external target="_blank"}
  - GPT-2 level: 3 hours on a 8xH100 GPU

# Generating Training Data

## Generating Training Data

- Before we can fine-tune a model, we need to generate training data
  - Data are conversations or input/output pairs that demonstrate **style**, **structure**, or **behavior** you want the model to adopt

## Generating Training Data

```json
{"messages": [{"role": "user", "content": "s = \"Hello\\nWorld\"\nprint(s)\n"}, {"role": "assistant", "content": "The code defines a string that contains the escape sequence \\n, which tells Python to start a new line when the string is displayed. When you run the print statement, \"Hello\" appears on one line and \"World\" appears on the next line, just like pressing Enter moves the cursor down in a text editor.\n\nImagine you are writing a story on a typewriter. When you finish a line, you press the \u201cEnter\u201d key to move to the next line and continue typing. The \\n character works the same way for strings in Python, signaling that the following text should start on a new line."}]}
```

## Generating Training Data

- Three datasets
  - **Training set:** What the model will learn from. Largest portion, about 70-80% of total data
  - **Validation set:** Separate dataset, used to monitor how well the model is generalizing. About 10-15%.
  - **Test set:** Separate dataset, provides an unbiased final measure of performance after training. About 10-15%

## Generating Training Data

- Diversity of training data
  - Needs to cover the range of inputs that the model will encounter in production.
  - A model trained only on short questions will struggle when users ask anything more complex
  - Datasets should have different dimensions

## Generating Training Data

- Diversity dimensions
  - Topics (areas, sub-domains)
  - Audience (e.g., school grade)
  - Length (e.g., short, med, long)
  - Formats (e.g., script vs. romanized)
  - Conversation turns (single / multi)
  - Negative answers (e.g., if implementing safety)
- Each of these can be weighted (e.g., 60% short, 20% med, 20% long)

## Generating Training Data

- How much data do you need? It depends :)
- Behaviour and style shifts: 50-500 high quality examples
- Multi-turn dialogue: 1K-10K examples
- Smaller models often need more examples
- Optimal dataset size is often discovered during training

## Generating Training Data

- Dataset Format
  - Typically JSON Lines (jsonl) - JSON objects separated with newline
- Converted to Hugging Face Datasets (and uploaded)
- During training, these get converted to the chat template/format used by the model

## Generating Training Data

- How do we generate this data?
  - Create the file by hand!
  - Generate **synthetic data** from a more capable model (and review for quality)
- Synthetic Data
  - "Generate n examples of students asking their teacher a geography question"
  - Often use structured outputs to map to jsonl conversational format

# Demo

Synthetic data generation using the generate-synthetic.ipynb notebook

# Looking Ahead

## Looking Ahead

- [This week's assignment!](https://simonguest.github.io/CS-394/src/06/assignment.html){.external target="_blank"}
- Use your generated synthetic data to fine-tune a small model
- Use W&B (Weights and Biases) to observe parameters during the training run
- Understand and create a model card, upload your model to Hugging Face and share

# References

## References
