{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d4aa350",
   "metadata": {},
   "source": [
    "# Generate Synthetic Training Data\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/simonguest/CS-394/blob/main/src/06/notebooks/generate-synthetic.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "<a target=\"_blank\" href=\"https://github.com/simonguest/CS-394/raw/refs/heads/main/src/06/notebooks/generate-synthetic.ipynb\">\n",
    "  <img src=\"https://img.shields.io/badge/Download_.ipynb-blue\" alt=\"Download .ipynb\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5572879c",
   "metadata": {},
   "source": [
    "## Data generation settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d29c9393",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN_EXAMPLES = 8000  # @param {type:\"number\"}\n",
    "NUM_VAL_EXAMPLES = 1000  # @param {type:\"number\"}\n",
    "NUM_TEST_EXAMPLES = 100 # @param {type:\"number\"}\n",
    "TEMPERATURE = 0.8  # @param {type:\"number\"}\n",
    "\n",
    "DATA_FOLDER = \"./.data/generated\"\n",
    "!mkdir -p {DATA_FOLDER}\n",
    "\n",
    "DATAGEN_MODEL = \"nvidia/nemotron-3-nano-30b-a3b:free\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672c9b3d",
   "metadata": {},
   "source": [
    "## Dataset diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a485a8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPICS = [\n",
    "    \"Strings\",\n",
    "    \"input()\", \n",
    "    \"print()\",\n",
    "    \"Creating variables\",\n",
    "    \"Concatenating strings\"\n",
    "    \"Lists\",\n",
    "    \"if/else constructs\",\n",
    "    \"in operator\",\n",
    "    \"list methods: append and remove\",\n",
    "    \"list methods: index, pop, and insert\",\n",
    "    \"list methods: slicing\",\n",
    "    \"list methods: deleting an item\",\n",
    "    \"for loops\",\n",
    "    \"range() and str()\",\n",
    "    \"== comparison operator\",\n",
    "    \"len() function\",\n",
    "    \"code commenting with #\",\n",
    "    \"Comparison operators: !=, >, >=, <, <=\",\n",
    "    \"String methods: .lower(), .upper(), .title(), .capitalize()\",\n",
    "    \"Using the newline character in strings\",\n",
    "    \"int()\",\n",
    "    \"float()\",\n",
    "    \"elif\",\n",
    "    \"import keyword\",\n",
    "    \"random module\",\n",
    "    \"while keyword\",\n",
    "    \"or and not operators\",\n",
    "    \"booleans\",\n",
    "    \"list methods: .clear(), .copy(), .count(), .extend(), .reverse(), .sort()\",\n",
    "    \"Dictionaries\",\n",
    "    \"Dictionary methods: .items(), .keys(), .values(), .update(), .pop()\",\n",
    "    \"Dictonary methods: .get(), .format()\",\n",
    "    \"String methods: .find(), .join(), .replace(), .split(), .swapcase()\",\n",
    "    \"Functions: using def and return keywords\", \n",
    "    \"Function methods: .isinstance()\",\n",
    "    \"Raising exceptions\",\n",
    "    \"Exceptions: TypeError() and ValueError()\",\n",
    "    \"Function keywords: as and from\",\n",
    "    \"The sys module\",\n",
    "    \"The with keyword\",\n",
    "    \"Tuples\",\n",
    "    \"The lambda keyword\",\n",
    "    \"The built-in map function\",\n",
    "    \"The time module\",\n",
    "    \"Built in methods: __init()__ and __str()__\",\n",
    "    \"Double underscore for private methods\",\n",
    "    \"Classes\"\n",
    "]\n",
    "\n",
    "CODE_LENGTH = [\n",
    "    \"short\",\n",
    "    \"paragraph\",\n",
    "    \"small_function\",\n",
    "    \"large_function\",\n",
    "]\n",
    "CODE_LENGTH_WEIGHTS = [0.25, 0.25, 0.25, 0.25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421c49e4",
   "metadata": {},
   "source": [
    "## Model for structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91787f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class CodeExplanation(BaseModel):\n",
    "    code: str\n",
    "    explanation: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712a3900",
   "metadata": {},
   "source": [
    "## Get OpenRouter API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc6fd261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "  from google.colab import userdata # type:ignore\n",
    "  os.environ['OPENROUTER_API_KEY'] = userdata.get('OPENROUTER_API_KEY')\n",
    "else:\n",
    "  load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218aa9db",
   "metadata": {},
   "source": [
    "## Conversation generation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ce9bb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n",
    ")\n",
    "\n",
    "def generate_completion(prompt: str) -> CodeExplanation | None:\n",
    "    response = client.responses.parse(\n",
    "        model=DATAGEN_MODEL,\n",
    "        input=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=TEMPERATURE,\n",
    "        stream=False,\n",
    "        text_format=CodeExplanation\n",
    "    )\n",
    "\n",
    "    return response.output_parsed\n",
    "\n",
    "def create_conversation(topic: str, code_length: str) -> CodeExplanation | None:\n",
    "    request = \"\"\n",
    "    if code_length == \"short\":\n",
    "        request = f\"2 - 4 lines of Python code about {topic}\"\n",
    "    elif code_length == \"paragraph\":\n",
    "        request = f\"3 - 6 lines of Python code about {topic}\"\n",
    "    elif code_length == \"small_function\":\n",
    "        request = f\"a small function (around 10 lines of Python code) about {topic}\"\n",
    "    elif code_length == \"large_function\":\n",
    "        request = f\"a large function (around 10 - 20 lines of Python code) about {topic}\"\n",
    "    else:\n",
    "        request = f\"a Python code example about {topic}\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Generate me {request}.\n",
    "\n",
    "        For this selection of code, generate a short 2 paragraph explanation of what the selected code does:\n",
    "        - The explanation should be suitable for a high school student learning Python.\n",
    "        - When it makes sense, the second paragraph of the explanation should use an analogy to help the student better understand the code.\n",
    "        - DO NOT wrap the code in a ```python block\n",
    "\n",
    "        Return the following:\n",
    "        1. The original code as a string. \n",
    "        2. Your explanation of what the selected code does as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    return generate_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fbaaf3",
   "metadata": {},
   "source": [
    "## Dataset generation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e79b6bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_dataset(num_examples: int, filename: str) -> None:\n",
    "  with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    for idx in tqdm(range(num_examples)):\n",
    "      topic = random.choice(TOPICS)\n",
    "      code_length = random.choices(CODE_LENGTH, weights=CODE_LENGTH_WEIGHTS)[0]\n",
    "\n",
    "      conversation = None\n",
    "      while conversation == None:\n",
    "        conversation = create_conversation(topic, code_length)\n",
    "        if conversation == None:\n",
    "          print(f\"Error generating conversation for example {idx}\")\n",
    "      \n",
    "      template = {\n",
    "          \"messages\": [\n",
    "              {\"role\": \"user\", \"content\": conversation.code},\n",
    "              {\n",
    "                  \"role\": \"assistant\",\n",
    "                  \"content\": conversation.explanation,\n",
    "              },\n",
    "          ]\n",
    "      }\n",
    "      line = json.dumps(template) + \"\\n\"\n",
    "      f.write(line)\n",
    "      f.flush()\n",
    "\n",
    "    f.flush()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98fa54d",
   "metadata": {},
   "source": [
    "## Generate all the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fc06c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:52<00:00,  5.24s/it]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TRAIN_FILE = f\"{DATA_FOLDER}/train_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.jsonl\"\n",
    "VALID_FILE = f\"{DATA_FOLDER}/valid_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.jsonl\"\n",
    "TEST_FILE = f\"{DATA_FOLDER}/test_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.jsonl\"\n",
    "\n",
    "generate_dataset(10, TRAIN_FILE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
