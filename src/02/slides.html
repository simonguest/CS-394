<!DOCTYPE html>
<html lang="en"><head>
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" integrity="sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2" crossorigin="anonymous"></script><script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-597958c53c93a607afca12fd375c57ed.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.26">

  <title>CS-394 – Week 2: Exploring Hosted LLMs</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
      }
    pre.numberSource { margin-left: 3em;  padding-left: 4px; }
    div.sourceCode
      { color: #24292e;  }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #24292e; } /* Normal */
    code span.al { color: #ff5555; font-weight: bold; } /* Alert */
    code span.an { color: #6a737d; } /* Annotation */
    code span.at { color: #d73a49; } /* Attribute */
    code span.bn { color: #005cc5; } /* BaseN */
    code span.bu { color: #d73a49; } /* BuiltIn */
    code span.cf { color: #d73a49; } /* ControlFlow */
    code span.ch { color: #032f62; } /* Char */
    code span.cn { color: #005cc5; } /* Constant */
    code span.co { color: #6a737d; } /* Comment */
    code span.cv { color: #6a737d; } /* CommentVar */
    code span.do { color: #6a737d; } /* Documentation */
    code span.dt { color: #d73a49; } /* DataType */
    code span.dv { color: #005cc5; } /* DecVal */
    code span.er { color: #ff5555; text-decoration: underline; } /* Error */
    code span.ex { color: #d73a49; font-weight: bold; } /* Extension */
    code span.fl { color: #005cc5; } /* Float */
    code span.fu { color: #6f42c1; } /* Function */
    code span.im { color: #032f62; } /* Import */
    code span.in { color: #6a737d; } /* Information */
    code span.kw { color: #d73a49; } /* Keyword */
    code span.op { color: #24292e; } /* Operator */
    code span.ot { color: #6f42c1; } /* Other */
    code span.pp { color: #d73a49; } /* Preprocessor */
    code span.re { color: #6a737d; } /* RegionMarker */
    code span.sc { color: #005cc5; } /* SpecialChar */
    code span.ss { color: #032f62; } /* SpecialString */
    code span.st { color: #032f62; } /* String */
    code span.va { color: #e36209; } /* Variable */
    code span.vs { color: #032f62; } /* VerbatimString */
    code span.wa { color: #ff5555; } /* Warning */
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-eeafb82a00776dbd0312b01cd21cfa25.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <meta name="mermaid-theme" content="neutral">
  <script src="../../site_libs/quarto-diagram/mermaid.min.js"></script>
  <script src="../../site_libs/quarto-diagram/mermaid-init.js"></script>
  <link href="../../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">
  <script src="https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js" integrity="sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx" crossorigin="anonymous"></script>
  
  <script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Week 2: Exploring Hosted LLMs</h1>

<div class="quarto-title-authors">
</div>

</section>
<section id="recap-of-last-weeks-lecture" class="slide level2">
<h2>Recap of Last Week’s Lecture</h2>
<ul>
<li class="fragment">Explored the history of vector embeddings and tokenization</li>
<li class="fragment">Understood the transformer architecture at a high level</li>
<li class="fragment">Used our first transformer to translate language</li>
<li class="fragment">Covered a brief history of early generative transformers</li>
<li class="fragment">Setup and used Colab, and became familiar with the basics of notebooks and Python</li>
</ul>
</section>
<section id="lesson-objectives" class="slide level2">
<h2>Lesson Objectives</h2>
<ul>
<li class="fragment">Understand the evolution and licensing of models from GPT-2 through to modern day</li>
<li class="fragment">Understand instruction-tuned models, how they work, and how to configure</li>
<li class="fragment">Setup and use OpenRouter for accessing hosted models</li>
<li class="fragment">Understand the OpenAI API specification, the request/response payload, parameters, streaming, and structured output</li>
<li class="fragment">Create and share a chatbot using a Gradio-based UI</li>
</ul>
</section>
<section>
<section id="from-gpt-2-to-gpt-3.5" class="title-slide slide level1 center">
<h1>From GPT-2 to GPT-3.5</h1>

</section>
<section id="from-gpt-2-to-gpt-3.5-1" class="slide level2">
<h2>From GPT-2 to GPT-3.5</h2>
<div class="cell" data-reveal="true" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<pre class="mermaid mermaid-js">timeline
    Feb 2019 : OpenAI releases GPT-2
             : 1.5B parameters
             : Initially withheld full model due to concerns about misuse
             : Demonstrates impressive text generation capabilities with minimal fine-tuning

    May 2020 : OpenAI releases GPT-3
             : 175B parameters
             : Demonstrates strong few-shot learning capabilities
             : Marks a significant leap in model capabilities and scale

    June 2020 : GPT-3 available through OpenAI API
              : Still a completion model, not instruction-tuned

    2021 : InstructGPT Development
          : Built on GPT-3 with RLHF fine-tuning
          : Trained to follow instructions and understand user intent
          : Key innovation enabling ChatGPT
    
    Jan 2021 : Anthropic Founded
             : Founded by Dario &amp; Daniela Amodei with ~7 senior OpenAI employees
             : Dario led GPT-2/3 development and co-invented RLHF

    Nov 2022 : ChatGPT Launch
              : Built on GPT-3.5 using RLHF
              : 1M+ users in 5 days
              : Sparked widespread interest in generative AI
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
<section id="completion-vs.-instruction-tuned" class="slide level2">
<h2>Completion vs.&nbsp;Instruction-Tuned</h2>
<ul>
<li class="fragment">Completion Model just predicts the next token
<ul>
<li class="fragment">Input prompt: <code>Mary had a little</code></li>
<li class="fragment">Max total tokens: <code>50</code></li>
<li class="fragment">Temperature: <code>0 - 1.0</code></li>
<li class="fragment">top_k: consider only the top k tokens in the response</li>
<li class="fragment">top_p: Nucleus sampling (probability cut off - 0 and 1.0)</li>
</ul></li>
<li class="fragment">Output
<ul>
<li class="fragment"><code>Mary had a little lamb, its fleece was white as snow...</code> (up to max tokens)</li>
</ul></li>
</ul>
</section>
<section id="completion-vs.-instruction-tuned-1" class="slide level2">
<h2>Completion vs.&nbsp;Instruction-Tuned</h2>
<ul>
<li class="fragment">You can’t really converse with it</li>
<li class="fragment"><code>What should I do on my upcoming trip to Paris?</code> (max tokens = 75)</li>
<li class="fragment"><code>What should I do on my upcoming trip to Paris? Please provide a detailed plan of action to help me plan my trip to Paris. 1. Research the best time to travel to Paris:</code></li>
</ul>
</section>
<section id="instruction-tuned-models" class="slide level2">
<h2>Instruction-Tuned Models</h2>
<ul>
<li class="fragment">Supervised Fine-Tuning
<ul>
<li class="fragment">Large datasets of questions/answers, tasks/completions, demonstrating helpful assistant behavior</li>
</ul></li>
<li class="fragment">RLHF (Reinforcement Learning from Human Feedback)
<ul>
<li class="fragment">Human raters rank different model responses, training a reward model</li>
</ul></li>
<li class="fragment">Chat Templates
<ul>
<li class="fragment">Structured format to distinguish speakers in a conversation: Typically <strong>system</strong>, <strong>user</strong>, and <strong>assistant</strong></li>
</ul></li>
</ul>
</section>
<section id="system-user-assistant" class="slide level2">
<h2>System, User, Assistant</h2>
<ul>
<li class="fragment"><strong>System</strong> prompt sets the intention for the model, guiding the output
<ul>
<li class="fragment">“You are a helpful assistant”</li>
<li class="fragment">“You help students with their math homework”</li>
<li class="fragment">“You help travelers make plans for their trips”</li>
<li class="fragment">Has to come first in the conversation</li>
<li class="fragment">Only one system prompt</li>
<li class="fragment">Optional for some models</li>
</ul></li>
</ul>
</section>
<section id="system-user-assistant-1" class="slide level2">
<h2>System, User, Assistant</h2>
<ul>
<li class="fragment"><strong>User</strong> prompt is the message (request) from the user
<ul>
<li class="fragment">“How many ’r’s in Strawberry?”</li>
<li class="fragment">“What is linear algebra?”</li>
<li class="fragment">“What should I do on my upcoming trip to Paris?”</li>
</ul></li>
<li class="fragment"><strong>Assistant</strong> prompt is the message (reply) from the model
<ul>
<li class="fragment">“There are three r’s in Strawberry”</li>
<li class="fragment">“Linear algebra is the branch of mathematics that studies vectors, etc.”</li>
<li class="fragment">“Here are some suggestions for your upcoming trip to Paris: 1. Explore the Louvre Museum: etc.”</li>
</ul></li>
</ul>
</section>
<section id="whats-a-chat-template" class="slide level2">
<h2>What’s a Chat Template?</h2>
<ul>
<li class="fragment">The format used to train instructional models on conversations involving system, user, and assistant prompts.</li>
<li class="fragment">Each model family uses a different format (there is no universal standard)</li>
<li class="fragment">Wrong format will likely generate nonsense/garbage</li>
</ul>
</section>
<section id="chatml-gpt-3.5-and-other-models" class="slide level2">
<h2>ChatML (GPT-3.5 and other models)</h2>
<pre><code>&lt;|im_start|&gt;system
You help travelers make plans for their trips&lt;|im_end|&gt;
&lt;|im_start|&gt;user
Hello&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant
Hi there! How can I help you?&lt;|im_end|&gt;
&lt;|im_start|&gt;user
What should I do on my upcoming trip to Paris?&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant
</code></pre>
</section>
<section id="chat-templates-in-practice" class="slide level2">
<h2>Chat Templates in Practice</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/02/notebooks/instruction-tuned.ipynb" data-notebook-title="Base Model vs. Instruction-Tuned Model" data-notebook-cellid="chat-template">
<div id="chat-template" class="cell" data-execution_count="46">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a></a><span class="co"># @title Qwen's Chat Template</span></span>
<span id="cb2-2"><a></a></span>
<span id="cb2-3"><a></a>messages <span class="op">=</span> [</span>
<span id="cb2-4"><a></a>    {<span class="st">"role"</span>: <span class="st">"system"</span>, <span class="st">"content"</span>: <span class="st">"You help travelers make plans for their trips"</span>},</span>
<span id="cb2-5"><a></a>    {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: <span class="st">"Hello"</span>},</span>
<span id="cb2-6"><a></a>    {<span class="st">"role"</span>: <span class="st">"assistant"</span>, <span class="st">"content"</span>: <span class="st">"Hi there!"</span>},</span>
<span id="cb2-7"><a></a>    {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: <span class="st">"What should I do on my upcoming trip to Paris?"</span>}</span>
<span id="cb2-8"><a></a>]</span>
<span id="cb2-9"><a></a></span>
<span id="cb2-10"><a></a>instruct_tokenizer.apply_chat_template(</span>
<span id="cb2-11"><a></a>    messages, </span>
<span id="cb2-12"><a></a>    tokenize<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb2-13"><a></a>    add_generation_prompt<span class="op">=</span><span class="va">True</span>  <span class="co"># Adds the assistant prompt</span></span>
<span id="cb2-14"><a></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="46">
<pre><code>'&lt;|im_start|&gt;system\nYou help travelers make plans for their trips&lt;|im_end|&gt;\n&lt;|im_start|&gt;user\nHello&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\nHi there!&lt;|im_end|&gt;\n&lt;|im_start|&gt;user\nWhat should I do on my upcoming trip to Paris?&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\n'</code></pre>
</div>
</div>
</div>
</section>
<section id="putting-this-together" class="slide level2">
<h2>Putting This Together</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/02/notebooks/instruction-tuned.ipynb" data-notebook-title="Base Model vs. Instruction-Tuned Model" data-notebook-cellid="base-model">
<div id="base-model" class="cell" data-execution_count="42">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a></a><span class="co"># @title Base (Completion) Model Output</span></span>
<span id="cb4-2"><a></a></span>
<span id="cb4-3"><a></a>base_inputs <span class="op">=</span> base_tokenizer(<span class="st">"What should I do on my upcoming trip to Paris?"</span>, return_tensors<span class="op">=</span><span class="st">"pt"</span>)</span>
<span id="cb4-4"><a></a>base_outputs <span class="op">=</span> base_model.generate(</span>
<span id="cb4-5"><a></a>    <span class="op">**</span>base_inputs,</span>
<span id="cb4-6"><a></a>    max_new_tokens<span class="op">=</span><span class="dv">150</span>,</span>
<span id="cb4-7"><a></a>    temperature<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb4-8"><a></a>    do_sample<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb4-9"><a></a>    pad_token_id<span class="op">=</span>base_tokenizer.eos_token_id</span>
<span id="cb4-10"><a></a>)</span>
<span id="cb4-11"><a></a>base_response <span class="op">=</span> base_tokenizer.decode(base_outputs[<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-12"><a></a><span class="bu">print</span>(base_response)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>What should I do on my upcoming trip to Paris? I think it would be better if you could give more specific information about where you plan to go and when you plan to arrive. Also, can you suggest any specific tips or recommendations for traveling to Paris other than walking around the city?

I'm sorry, but as an AI language model, I don't have any specific information about your upcoming trip to Paris. However, I can suggest some general tips and recommendations for traveling to Paris other than walking around the city:

1. Plan your itinerary ahead of time to avoid getting lost or getting in over your head.
2. Book your flights or accommodations in advance to avoid being stuck in traffic or waiting for a delayed flight.
3. Purchase a travel insurance policy to protect your belongings and reduce the risk of</code></pre>
</div>
</div>
</div>
</section>
<section id="putting-this-together-1" class="slide level2">
<h2>Putting This Together</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/02/notebooks/instruction-tuned.ipynb" data-notebook-title="Base Model vs. Instruction-Tuned Model" data-notebook-cellid="it-model">
<div id="it-model" class="cell" data-execution_count="43">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a></a><span class="co"># @title Instruction-Tuned Model Output</span></span>
<span id="cb6-2"><a></a></span>
<span id="cb6-3"><a></a>messages <span class="op">=</span> [</span>
<span id="cb6-4"><a></a>    {<span class="st">"role"</span>: <span class="st">"system"</span>, <span class="st">"content"</span>: <span class="st">"You help travelers make plans for their trips."</span>},</span>
<span id="cb6-5"><a></a>    {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: <span class="st">"Hello"</span>},</span>
<span id="cb6-6"><a></a>    {<span class="st">"role"</span>: <span class="st">"assistant"</span>, <span class="st">"content"</span>: <span class="st">"Hi there!"</span>},</span>
<span id="cb6-7"><a></a>    {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: <span class="st">"What should I do on my upcoming trip to Paris?"</span>}</span>
<span id="cb6-8"><a></a>]</span>
<span id="cb6-9"><a></a>instruct_text <span class="op">=</span> instruct_tokenizer.apply_chat_template(</span>
<span id="cb6-10"><a></a>    messages, tokenize<span class="op">=</span><span class="va">False</span>, add_generation_prompt<span class="op">=</span><span class="va">True</span></span>
<span id="cb6-11"><a></a>)</span>
<span id="cb6-12"><a></a>instruct_inputs <span class="op">=</span> instruct_tokenizer(instruct_text, return_tensors<span class="op">=</span><span class="st">"pt"</span>)</span>
<span id="cb6-13"><a></a>instruct_outputs <span class="op">=</span> instruct_model.generate(</span>
<span id="cb6-14"><a></a>    <span class="op">**</span>instruct_inputs,</span>
<span id="cb6-15"><a></a>    max_new_tokens<span class="op">=</span><span class="dv">150</span>,</span>
<span id="cb6-16"><a></a>    temperature<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb6-17"><a></a>    do_sample<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-18"><a></a>    pad_token_id<span class="op">=</span>instruct_tokenizer.eos_token_id,</span>
<span id="cb6-19"><a></a>)</span>
<span id="cb6-20"><a></a>instruct_response <span class="op">=</span> instruct_tokenizer.decode(</span>
<span id="cb6-21"><a></a>    instruct_outputs[<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">True</span></span>
<span id="cb6-22"><a></a>)</span>
<span id="cb6-23"><a></a><span class="bu">print</span>(instruct_response)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>system
You help travelers make plans for their trips.
user
Hello
assistant
Hi there!
user
What should I do on my upcoming trip to Paris?
assistant
Great question! On your next trip to Paris, you can start by visiting the iconic Eiffel Tower and the Louvre Museum. Don't miss exploring the Notre-Dame Cathedral and its stunning stained glass windows. For a bit of a break, consider visiting Montmartre for some beautiful art and architecture. If you're looking for something more adventurous, you could take a stroll through the charming streets of Montmartre or explore the vibrant nightlife of Le Marais. Have fun planning your trip to Paris!</code></pre>
</div>
</div>
</div>
</section></section>
<section id="demo" class="title-slide slide level1 center">
<h1>Demo</h1>
<p>Base vs.&nbsp;Instruction-Tuned Model notebook in Colab</p>
</section>

<section id="hands-on" class="title-slide slide level1 center">
<h1>Hands-On</h1>
<p>Experiment with your own phrases in the instruction-tuned.ipynb notebook</p>
</section>

<section>
<section id="model-evolution" class="title-slide slide level1 center">
<h1>Model Evolution</h1>

</section>
<section id="model-evolution-gpt-3.5-onwards" class="slide level2">
<h2>Model Evolution (GPT 3.5 onwards)</h2>
<div class="cell" data-reveal="true" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<pre class="mermaid mermaid-js">timeline
    Nov 2022 : ChatGPT Launch
                  : Built on GPT-3.5 using RLHF
                  : 1M+ users in 5 days
                  : Sparked widespread interest in generative AI

    Feb 2023 : Llama 1 Released
                  : Meta's LLaMA (7B, 13B, 33B, 65B parameters)
                  : 13B model exceeded GPT-3 (175B) on most benchmarks
                  : Limited researcher access
                  : Text completion only (Alpaca fine-tune added instructions)

    Jul 2023 : Llama 2 Released
              : Available in 7B, 13B, 70B sizes
              : Trained on 40% more data than Llama 1
              : First open-weights Llama for commercial use
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
<section id="closed-vs.-open-models" class="slide level2">
<h2>Closed vs.&nbsp;Open Models</h2>
<ul>
<li class="fragment"><strong>Closed Source:</strong>
<ul>
<li class="fragment">Hosted models</li>
<li class="fragment">No ability to inspect the weights of the models</li>
<li class="fragment">No ability to download the models</li>
<li class="fragment">OpenAI GPT-5, Claude Sonnet 4.5, Google’s Gemini</li>
<li class="fragment">Very large models; often referred to as <strong>foundational</strong> models or <strong>frontier</strong> models</li>
</ul></li>
</ul>
</section>
<section id="closed-vs.-open-models-1" class="slide level2">
<h2>Closed vs.&nbsp;Open Models</h2>
<ul>
<li class="fragment"><strong>Open Weight:</strong>
<ul>
<li class="fragment">Downloadable model files</li>
<li class="fragment">You can download the model files with pretrained weights, but no training data</li>
<li class="fragment">No training data == No ability to recreate the model from scratch</li>
<li class="fragment">Meta’s Llama, Google’s Gemma, Alibaba’s Qwen, OpenAI gpt-oss-120b</li>
<li class="fragment">Range from small to medium in size (1Gb - 500Gb+)</li>
</ul></li>
</ul>
</section>
<section id="closed-vs.-open-models-2" class="slide level2">
<h2>Closed vs.&nbsp;Open Models</h2>
<ul>
<li class="fragment"><strong>Open Source:</strong>
<ul>
<li class="fragment">Models with access to the training data set</li>
<li class="fragment">You can download the model files with pretrained weights <strong>and</strong> the training data used to train it</li>
<li class="fragment">i.e., you could create the model from scratch</li>
<li class="fragment">Examples: AI2’s OLMo</li>
</ul></li>
</ul>
</section>
<section id="accessing-closed-models" class="slide level2">
<h2>Accessing Closed Models</h2>
<ul>
<li class="fragment">Consumer Website / App
<ul>
<li class="fragment">e.g., ChatGPT website or AppStore App</li>
<li class="fragment">Limited free tier; monthly subscription for more usage</li>
</ul></li>
<li class="fragment">API Access
<ul>
<li class="fragment">OpenAI’s API Platform; Create a developer account</li>
<li class="fragment">Credit card required</li>
<li class="fragment">Charged for tokens sent to the model and tokens returned from the model</li>
<li class="fragment">GPT 5.2 Chat = $1.75 per million tokens input; $14 per million tokens output</li>
</ul></li>
</ul>
</section>
<section id="accessing-open-models" class="slide level2">
<h2>Accessing Open Models</h2>
<ul>
<li class="fragment">Download and run on your own hardware
<ul>
<li class="fragment">Or download them and run them on Colab, as we’ve been doing in our demos</li>
<li class="fragment">(We’ll be covering this later on in the course)</li>
</ul></li>
<li class="fragment">Also access them (via an API), hosted on someone else’s hardware</li>
</ul>
</section></section>
<section>
<section id="calling-models-via-apis" class="title-slide slide level1 center">
<h1>Calling Models via APIs</h1>

</section>
<section id="openai-chat-completions-api" class="slide level2">
<h2>OpenAI Chat Completions API</h2>
<ul>
<li class="fragment">2020: OpenAI launched GPT-3 API with a <code>/completions</code> endpoint.
<ul>
<li class="fragment">First major LLM API</li>
</ul></li>
<li class="fragment">2022: ChatGPT launch; massive adoption</li>
<li class="fragment">2023 <code>/chat/completions</code> endpoint released, becomes the dominant interface</li>
<li class="fragment">2023-2024: Other providers use the same API format for their own models vs.&nbsp;inventing their own
<ul>
<li class="fragment">Build on the OpenAI developer ecosystem</li>
<li class="fragment">“OpenAI-compatible” became a selling point</li>
</ul></li>
</ul>
</section>
<section id="openai-chat-completions-api-1" class="slide level2">
<h2>OpenAI Chat Completions API</h2>
<ul>
<li class="fragment">Who uses the OpenAI Chat Completions API format?
<ul>
<li class="fragment">Anthropic (Claude API is very similar, with minor differences)</li>
<li class="fragment">OpenRouter, an inference provider for many models</li>
<li class="fragment">Open source tools: LiteLLM, LangChain</li>
<li class="fragment">Local serving: Ollama, vLLM, llama.cpp are all “OpenAI-compatible”</li>
</ul></li>
</ul>
</section>
<section id="using-the-chat-completions-api" class="slide level2">
<h2>Using the Chat Completions API</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/02/notebooks/chat-completion-openai.ipynb" data-notebook-title="Chat Completion API (via OpenAI)" data-notebook-cellid="init">
<div id="init" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="0c9cd662-ed23-4cda-979e-c02a10b55eab">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a></a><span class="co"># @title Call OpenAI via the SDK</span></span>
<span id="cb8-2"><a></a></span>
<span id="cb8-3"><a></a><span class="im">import</span> openai</span>
<span id="cb8-4"><a></a><span class="im">import</span> httpx</span>
<span id="cb8-5"><a></a></span>
<span id="cb8-6"><a></a><span class="co"># Initialize the OpenAI client with event hooks</span></span>
<span id="cb8-7"><a></a>client <span class="op">=</span> openai.OpenAI(</span>
<span id="cb8-8"><a></a>    api_key<span class="op">=</span>OPENAI_API_KEY,</span>
<span id="cb8-9"><a></a>    http_client<span class="op">=</span>httpx.Client(event_hooks<span class="op">=</span>{<span class="st">"request"</span>: [log_request]}),</span>
<span id="cb8-10"><a></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</section>
<section id="using-the-chat-completions-api-1" class="slide level2">
<h2>Using the Chat Completions API</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/02/notebooks/chat-completion-openai.ipynb" data-notebook-title="Chat Completion API (via OpenAI)" data-notebook-cellid="request">
<div id="request" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a></a>response <span class="op">=</span> client.chat.completions.create(</span>
<span id="cb9-2"><a></a>    model<span class="op">=</span><span class="st">"gpt-5"</span>,</span>
<span id="cb9-3"><a></a>    messages<span class="op">=</span>[</span>
<span id="cb9-4"><a></a>        {<span class="st">"role"</span>: <span class="st">"system"</span>, <span class="st">"content"</span>: <span class="st">"You help travelers make plans for their trips."</span>},</span>
<span id="cb9-5"><a></a>        {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: <span class="st">"Hello"</span>},</span>
<span id="cb9-6"><a></a>        {<span class="st">"role"</span>: <span class="st">"assistant"</span>, <span class="st">"content"</span>: <span class="st">"Hi there!"</span>},</span>
<span id="cb9-7"><a></a>        {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: <span class="st">"What should I do on my upcoming trip to Paris?"</span>},</span>
<span id="cb9-8"><a></a>    ],</span>
<span id="cb9-9"><a></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
=== REQUEST ===
URL: https://api.openai.com/v1/chat/completions
Method: POST

Body:
{
  "messages": [
    {
      "role": "system",
      "content": "You help travelers make plans for their trips."
    },
    {
      "role": "user",
      "content": "Hello"
    },
    {
      "role": "assistant",
      "content": "Hi there!"
    },
    {
      "role": "user",
      "content": "What should I do on my upcoming trip to Paris?"
    }
  ],
  "model": "gpt-5"
}
==================================================</code></pre>
</div>
</div>
</div>
</section>
<section id="using-the-chat-completions-api-2" class="slide level2">
<h2>Using the Chat Completions API</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/02/notebooks/chat-completion-openai.ipynb" data-notebook-title="Chat Completion API (via OpenAI)" data-notebook-cellid="response">
<div id="response" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== RESPONSE ==="</span>)</span>
<span id="cb11-2"><a></a><span class="bu">print</span>(response.model_dump_json(indent<span class="op">=</span><span class="dv">2</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
=== RESPONSE ===
{
  "id": "chatcmpl-CuVn7EYuGJUEUEQ18Cl0SM2nNz9Mj",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "Awesome! I can tailor a plan, but a few quick questions help:\n- When are you going and for how many days?\n- First time in Paris?\n- Main interests (art, food, fashion, history, photography, nightlife, kid-friendly, etc.) and preferred pace (relaxed vs. packed)?\n- Any must-sees or hard no’s?\n- Rough budget and food needs (vegetarian, kosher/halal, allergies)?\n- Where are you staying (neighborhood) and are day trips okay (Versailles, Champagne, Giverny, Disneyland)?\n\nIf you want a quick starter plan, here’s a flexible 4-day outline you can reshuffle by weather and museum closures:\n\nDay 1 – Islands + Latin Quarter\n- Île de la Cité: Notre-Dame exterior, Sainte-Chapelle (timed ticket), Conciergerie.\n- Stroll the Latin Quarter: Shakespeare &amp; Company, Sorbonne, Luxembourg Gardens.\n- Evening: Seine cruise or sunset along the river.\n\nDay 2 – Louvre to Arc de Triomphe\n- Morning: Louvre (timed entry). Tuileries and Palais-Royal gardens.\n- Covered passages (Véronique/Grand Cerf/Jouffroy) and Opéra Garnier.\n- Sunset view: Arc de Triomphe rooftop or Galeries Lafayette/Printemps terrace.\n\nDay 3 – Montmartre + Left Bank art\n- Montmartre: Sacré-Cœur, Place du Tertre, quieter backstreets (Rue de l’Abreuvoir).\n- Afternoon: Musée d’Orsay and/or Orangerie.\n- Evening: Saint-Germain wine bar or jazz.\n\nDay 4 – Le Marais or Day Trip\n- Marais walk: Place des Vosges, Musée Carnavalet, Picasso Museum (check hours), Jewish quarter, trendy boutiques.\n- Optional day trip: Versailles (palace + gardens; get the timed passport ticket).\n- Night: Eiffel Tower area (view from Trocadéro or Champ de Mars; book tower tickets if going up).\n\nOther great adds by interest\n- Art/architecture: Rodin Museum; Bourse de Commerce; Fondation Louis Vuitton. Note: check Centre Pompidou’s renovation status.\n- Food: Morning market (Aligre or Rue Cler), cheese/wine tasting, pastry crawl, bistro lunch, cooking class.\n- Unique: Catacombs (book ahead), Père Lachaise Cemetery, Canal Saint-Martin, covered markets (Le Marché des Enfants Rouges).\n- With kids: Jardin des Plantes (zoo + galleries), Cité des Sciences, Jardin d’Acclimatation, Parc de la Villette.\n- Day trips: Giverny (Apr–Oct), Reims/Epernay for Champagne, Fontainebleau, Auvers-sur-Oise, Disneyland Paris.\n\nBook these in advance\n- Eiffel Tower, Louvre, Sainte-Chapelle, Catacombs, Versailles, Palais Garnier tours, popular restaurants.\n- Consider the Paris Museum Pass (2/4/6 days) if you’ll visit several museums; the Louvre still needs a timed reservation even with the pass.\n\nPractical tips\n- Closures: Many museums close one day/week (e.g., Orsay Mon, some Tue). Check hours.\n- Getting around: The Métro is fastest. Use a contactless bank card to tap in, or get a reloadable Navigo Easy. For a Monday–Sunday stay with lots of rides, a Navigo Découverte weekly pass can be good value.\n- Dining: Reserve for dinner, especially weekends. Tipping is minimal (service included); round up or leave 5–10% for great service.\n- Safety: Watch for pickpockets in crowded areas and on the Metro.\n\nShare your dates, length of stay, and interests, and I’ll turn this into a detailed day-by-day plan with mapped routes and restaurant picks near each stop.",
        "refusal": null,
        "role": "assistant",
        "annotations": [],
        "audio": null,
        "function_call": null,
        "tool_calls": null
      }
    }
  ],
  "created": 1767584609,
  "model": "gpt-5-2025-08-07",
  "object": "chat.completion",
  "service_tier": "default",
  "system_fingerprint": null,
  "usage": {
    "completion_tokens": 2224,
    "prompt_tokens": 44,
    "total_tokens": 2268,
    "completion_tokens_details": {
      "accepted_prediction_tokens": 0,
      "audio_tokens": 0,
      "reasoning_tokens": 1408,
      "rejected_prediction_tokens": 0
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 0
    }
  }
}</code></pre>
</div>
</div>
</div>
</section></section>
<section>
<section id="calling-other-models" class="title-slide slide level1 center">
<h1>Calling Other Models</h1>

</section>
<section id="calling-other-models-1" class="slide level2">
<h2>Calling Other Models</h2>
<ul>
<li class="fragment">We could just duplicate our notebook, change the URL to another provider (e.g., Claude, Google, etc.), but:
<ul>
<li class="fragment">A separate account with each provider</li>
<li class="fragment">A separate credit card with each provider</li>
<li class="fragment">A separate API key to use for each provider</li>
<li class="fragment">Duplicate notebooks for each provider</li>
</ul></li>
<li class="fragment">Wouldn’t it be nice to have a single service (inference provider) that exposed lots of different models</li>
</ul>
</section>
<section id="introducing-openrouter" class="slide level2">
<h2>Introducing OpenRouter</h2>
<ul>
<li class="fragment">Introducing OpenRouter (https://openrouter.ai)
<ul>
<li class="fragment">A unified API to hundreds of AI models through a single endpoint</li>
<li class="fragment">(Using OpenAI’s Chat Completion API)</li>
<li class="fragment">OpenAI, Claude, Gemini, Grok, Nova, Llama, DeepSeek, Qwen, and many others.</li>
<li class="fragment">Pay per API call, often same cost as the provider</li>
<li class="fragment">Newer APIs tend to be free for a short period</li>
</ul></li>
</ul>
</section>
<section id="using-openrouter" class="slide level2">
<h2>Using OpenRouter</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/02/notebooks/chat-completion-openrouter.ipynb" data-notebook-title="Chat Completion API (via OpenRouter)" data-notebook-cellid="init">
<div id="init" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="0c9cd662-ed23-4cda-979e-c02a10b55eab" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a></a><span class="co"># @title Call OpenAI via the SDK</span></span>
<span id="cb13-2"><a></a></span>
<span id="cb13-3"><a></a><span class="im">import</span> openai</span>
<span id="cb13-4"><a></a><span class="im">import</span> httpx</span>
<span id="cb13-5"><a></a></span>
<span id="cb13-6"><a></a><span class="co"># Initialize the OpenAI client with event hooks</span></span>
<span id="cb13-7"><a></a>client <span class="op">=</span> openai.OpenAI(</span>
<span id="cb13-8"><a></a>    base_url<span class="op">=</span><span class="st">'https://openrouter.ai/api/v1'</span>,</span>
<span id="cb13-9"><a></a>    api_key<span class="op">=</span>OPENROUTER_API_KEY,</span>
<span id="cb13-10"><a></a>    http_client<span class="op">=</span>httpx.Client(event_hooks<span class="op">=</span>{<span class="st">"request"</span>: [log_request]}),</span>
<span id="cb13-11"><a></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</section>
<section id="using-openrouter-1" class="slide level2">
<h2>Using OpenRouter</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/02/notebooks/chat-completion-openrouter.ipynb" data-notebook-title="Chat Completion API (via OpenRouter)" data-notebook-cellid="request">
<div id="request" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a></a>MODEL <span class="op">=</span> <span class="st">'openai/gpt-5.2-chat'</span> <span class="co">#@param ["openai/gpt-5.2-chat", "anthropic/claude-sonnet-4.5", "google/gemini-2.5-pro"]</span></span>
<span id="cb14-2"><a></a></span>
<span id="cb14-3"><a></a>response <span class="op">=</span> client.chat.completions.create(</span>
<span id="cb14-4"><a></a>    model<span class="op">=</span>MODEL,</span>
<span id="cb14-5"><a></a>    messages<span class="op">=</span>[</span>
<span id="cb14-6"><a></a>        {<span class="st">"role"</span>: <span class="st">"system"</span>, <span class="st">"content"</span>: <span class="st">"You help travelers make plans for their trips."</span>},</span>
<span id="cb14-7"><a></a>        {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: <span class="st">"Hello"</span>},</span>
<span id="cb14-8"><a></a>        {<span class="st">"role"</span>: <span class="st">"assistant"</span>, <span class="st">"content"</span>: <span class="st">"Hi there!"</span>},</span>
<span id="cb14-9"><a></a>        {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: <span class="st">"What should I do on my upcoming trip to Paris?"</span>},</span>
<span id="cb14-10"><a></a>    ],</span>
<span id="cb14-11"><a></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
=== REQUEST ===
URL: https://openrouter.ai/api/v1/chat/completions
Method: POST

Body:
{
  "messages": [
    {
      "role": "system",
      "content": "You help travelers make plans for their trips."
    },
    {
      "role": "user",
      "content": "Hello"
    },
    {
      "role": "assistant",
      "content": "Hi there!"
    },
    {
      "role": "user",
      "content": "What should I do on my upcoming trip to Paris?"
    }
  ],
  "model": "openai/gpt-5.2-chat"
}
==================================================</code></pre>
</div>
</div>
</div>
</section>
<section id="using-openrouter-2" class="slide level2">
<h2>Using OpenRouter</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/02/notebooks/chat-completion-openrouter.ipynb" data-notebook-title="Chat Completion API (via OpenRouter)" data-notebook-cellid="response">
<div id="response" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== RESPONSE ==="</span>)</span>
<span id="cb16-2"><a></a><span class="bu">print</span>(response.model_dump_json(indent<span class="op">=</span><span class="dv">2</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
=== RESPONSE ===
{
  "id": "gen-1767585819-snubWxcK6sJM3RdE9rJX",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "Paris has something for almost every kind of traveler! Here’s a well‑rounded starting plan, and then I can tailor it more if you tell me your interests, travel dates, and how long you’ll be there.\n\n### Must‑See Highlights\n- **Eiffel Tower** – Go up for the views or enjoy it from below at Trocadéro or Champ de Mars.\n- **Louvre Museum** – Even if you don’t love museums, seeing the Mona Lisa and the building itself is worth it.\n- **Notre‑Dame Cathedral** – Admire the exterior and surroundings; interior access is gradually reopening.\n- **Montmartre &amp; Sacré‑Cœur** – Charming streets, artists, and great city views.\n\n### Classic Paris Experiences\n- **Stroll along the Seine** – Especially at sunset.\n- **Café culture** – Sit at a café with a coffee or glass of wine and people‑watch.\n- **Boulangeries &amp; pastries** – Try croissants, pain au chocolat, macarons.\n- **Seine river cruise** – Relaxing and great for first‑time visitors.\n\n### Art, History &amp; Culture\n- **Musée d’Orsay** – Impressionist masterpieces in a stunning former train station.\n- **Le Marais** – Historic district with boutiques, museums, and lively streets.\n- **Latin Quarter** – Bookshops, old streets, and student energy.\n\n### Food &amp; Drink\n- **Bistro dining** – Try classic French dishes like boeuf bourguignon or duck confit.\n- **Food markets** – Marché des Enfants Rouges is a favorite.\n- **Wine &amp; cheese tasting** – Many small shops offer guided tastings.\n\n### Day Trips (if you have extra time)\n- **Versailles** – Palace and gardens (half‑day or full‑day trip).\n- **Giverny** – Monet’s gardens (spring/summer).\n- **Champagne region** – For wine lovers.\n\n### Practical Tips\n- Buy museum tickets in advance.\n- Walk as much as possible—Paris is very walkable.\n- Learn a few French phrases; locals appreciate the effort.\n\nIf you’d like, tell me:\n- How many days you’ll be there  \n- Your interests (food, art, history, shopping, nightlife, romance, family travel)  \n- Your budget level  \n\nAnd I’ll create a personalized day‑by‑day itinerary for you.",
        "refusal": null,
        "role": "assistant",
        "annotations": null,
        "audio": null,
        "function_call": null,
        "tool_calls": null,
        "reasoning": null
      },
      "native_finish_reason": "completed"
    }
  ],
  "created": 1767585819,
  "model": "openai/gpt-5.2-chat",
  "object": "chat.completion",
  "service_tier": null,
  "system_fingerprint": null,
  "usage": {
    "completion_tokens": 506,
    "prompt_tokens": 44,
    "total_tokens": 550,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": null,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null,
      "image_tokens": 0
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 0,
      "video_tokens": 0
    },
    "cost": 0.007161,
    "is_byok": false,
    "cost_details": {
      "upstream_inference_cost": null,
      "upstream_inference_prompt_cost": 0.000077,
      "upstream_inference_completions_cost": 0.007084
    }
  },
  "provider": "OpenAI"
}</code></pre>
</div>
</div>
</div>
</section></section>
<section id="demo-1" class="title-slide slide level1 center">
<h1>Demo</h1>
<p>OpenRouter overview, OpenRouter Notebook, and setting secrets in Colab</p>
</section>

<section id="hands-on-1" class="title-slide slide level1 center">
<h1>Hands-On</h1>
<p>Register for an OpenRouter account, create an API key, import into the OpenRouter Notebook (chat-completion-openrouter.ipynb) and experiment with different models</p>
</section>

<section>
<section id="token-streaming-and-structured-output" class="title-slide slide level1 center">
<h1>Token Streaming and Structured Output</h1>

</section>
<section id="token-streaming" class="slide level2">
<h2>Token Streaming</h2>
<ul>
<li class="fragment">In our notebooks, responses can take a few seconds to be returned
<ul>
<li class="fragment">Not the best user experience, especially for consumer products</li>
</ul></li>
<li class="fragment">Need a way to support streaming of tokens as they are generated (a.k.a. “typewriter effect”)
<ul>
<li class="fragment">Streaming added to Chat Completions API in early 2023</li>
<li class="fragment">Supported by other major vendors (Anthropic, Cohere, etc.)</li>
<li class="fragment">Now expected as a baseline feature</li>
</ul></li>
</ul>
</section>
<section id="how-does-token-streaming-work" class="slide level2">
<h2>How Does Token Streaming Work?</h2>
<ul>
<li class="fragment">Uses SSE (Server-Sent Events)
<ul>
<li class="fragment">Unidirectional (server to client)</li>
<li class="fragment">Uses standard HTTP/1.1 or HTTP/2</li>
<li class="fragment">Server sends a response with a <code>text/event-stream</code> MIME type</li>
<li class="fragment">Client uses built-in <code>EventSource</code> API to open the connection, listen to messages, and handle events.</li>
</ul></li>
</ul>
</section>
<section id="sse-data-format" class="slide level2">
<h2>SSE Data Format</h2>
<pre><code>data: {"choices":[{"delta":{"content":"Hello"}}]}

data: {"choices":[{"delta":{"content":" world"}}]}
  
data: [DONE]</code></pre>
<p>Data sent as chunks, prefixed with <code>data:</code> and separated by double newlines</p>
</section>
<section id="implementing-token-streaming" class="slide level2">
<h2>Implementing Token Streaming</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/02/notebooks/token-streaming.ipynb" data-notebook-title="Token Streaming" data-notebook-cellid="request">
<div id="request" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a></a>MODEL <span class="op">=</span> <span class="st">'openai/gpt-5.2-chat'</span> <span class="co">#@param ["openai/gpt-5.2-chat", "anthropic/claude-sonnet-4.5", "google/gemini-2.5-pro"]</span></span>
<span id="cb19-2"><a></a></span>
<span id="cb19-3"><a></a>response <span class="op">=</span> client.chat.completions.create(</span>
<span id="cb19-4"><a></a>    model<span class="op">=</span>MODEL,</span>
<span id="cb19-5"><a></a>    messages<span class="op">=</span>[</span>
<span id="cb19-6"><a></a>        {<span class="st">"role"</span>: <span class="st">"system"</span>, <span class="st">"content"</span>: <span class="st">"You help travelers make plans for their trips."</span>},</span>
<span id="cb19-7"><a></a>        {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: <span class="st">"Hello"</span>},</span>
<span id="cb19-8"><a></a>        {<span class="st">"role"</span>: <span class="st">"assistant"</span>, <span class="st">"content"</span>: <span class="st">"Hi there!"</span>},</span>
<span id="cb19-9"><a></a>        {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: <span class="st">"What should I do on my upcoming trip to Paris?"</span>},</span>
<span id="cb19-10"><a></a>    ],</span>
<span id="cb19-11"><a></a>    stream<span class="op">=</span><span class="va">True</span>, <span class="co"># Enable streaming</span></span>
<span id="cb19-12"><a></a>)</span>
<span id="cb19-13"><a></a></span>
<span id="cb19-14"><a></a><span class="co"># Iterate through the stream and print each token as it arrives</span></span>
<span id="cb19-15"><a></a><span class="cf">for</span> chunk <span class="kw">in</span> response:</span>
<span id="cb19-16"><a></a>    <span class="co"># Each chunk contains a delta with the new content</span></span>
<span id="cb19-17"><a></a>    <span class="cf">if</span> chunk.choices[<span class="dv">0</span>].delta.content <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb19-18"><a></a>        token <span class="op">=</span> chunk.choices[<span class="dv">0</span>].delta.content</span>
<span id="cb19-19"><a></a>        <span class="bu">print</span>(token, end<span class="op">=</span><span class="st">''</span>, flush<span class="op">=</span><span class="va">True</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Paris has something for almost every type of traveler, so I’ll give you a well‑rounded starting plan. If you want something more tailored (food, art, budget, family‑friendly, etc.), just tell me.

### Must‑See Classics
- **Eiffel Tower** – Go up if it’s your first time, or enjoy views from **Trocadéro** or **Champ de Mars**.
- **Louvre Museum** – Even a 2–3 hour focused visit is worthwhile (book tickets in advance).
- **Notre‑Dame Cathedral** – Admire the exterior and nearby **Île de la Cité**; check reopening status for interior access.
- **Arc de Triomphe** – Climb to the top for one of the best city views.

### Neighborhoods to Explore
- **Montmartre** – Artistic vibes, Sacré‑Cœur, charming streets.
- **Le Marais** – Trendy shops, historic mansions, great food.
- **Latin Quarter** – Lively, student energy, bookshops, cafés.
- **Saint‑Germain‑des‑Prés** – Classic cafés and upscale shopping.

### Food &amp; Drink Experiences
- Eat at a **local bistro** (look for a fixed‑price *menu du jour*).
- Try **croissants &amp; pain au chocolat** from a neighborhood bakery.
- Visit a **fromagerie** and **wine bar**.
- Enjoy café culture: sit outside, order a coffee or wine, and people‑watch.
- Don’t miss **crêpes**, **macarons**, and **cheese**.

### Cultural &amp; Unique Experiences
- **Seine River cruise** (especially at night).
- **Musée d’Orsay** for Impressionist art.
- **Versailles** day trip for palace and gardens.
- **Cooking class** or **food tour**.
- Wander without a plan—Paris is best discovered on foot.

### Practical Tips
- Buy museum tickets in advance to skip lines.
- Learn a few French phrases—it goes a long way.
- Dress comfortably but stylishly; Parisians walk a lot.
- Use public transport (metro is fast and affordable).

If you’d like, tell me:
- How many days you’ll be there  
- Time of year  
- Your interests (food, museums, nightlife, romance, budget travel)

I can build you a **day‑by‑day itinerary** just for your trip.</code></pre>
</div>
</div>
</div>
</section></section>
<section>
<section id="structured-output" class="title-slide slide level1 center">
<h1>Structured Output</h1>

</section>
<section id="structured-output-1" class="slide level2">
<h2>Structured Output</h2>
<ul>
<li class="fragment">So far, the models have generated non-structured output (i.e., free-form text)</li>
<li class="fragment">Sometimes, paragraph. Sometimes, numbered list.</li>
<li class="fragment">Sometimes, you just need structure
<ul>
<li class="fragment">“Return your result in JSON format”</li>
<li class="fragment">“Give me the coordinates for Paris”</li>
<li class="fragment">“What’s the temperature in Paris right now?”</li>
</ul></li>
</ul>
</section>
<section id="structured-output-2" class="slide level2">
<h2>Structured Output</h2>
<ul>
<li class="fragment">You can try to use the system prompt
<ul>
<li class="fragment">“Return the result in JSON only”</li>
</ul></li>
<li class="fragment">But… it doesn’t always work
<ul>
<li class="fragment">Early/small models struggle with correct JSON formatting</li>
<li class="fragment">Even larger models make mistakes (e.g., missing closing brace)</li>
</ul></li>
<li class="fragment">Sometimes the models just forget!
<ul>
<li class="fragment">“RETURN THE RESULT IN JSON ONLY. NO OTHER TEXT!!!”</li>
</ul></li>
</ul>
</section>
<section id="structured-output-in-openai-api" class="slide level2">
<h2>Structured Output in OpenAI API</h2>
<ul>
<li class="fragment">Nov 2023: OpenAI added JSON mode
<ul>
<li class="fragment"><code>response_format: {"type": "json_object"}</code></li>
<li class="fragment">Guaranteed valid JSON, but didn’t enforce schema</li>
<li class="fragment">Sometimes mixed up/missed fields</li>
</ul></li>
<li class="fragment">Aug 2024: <strong>Structured Outputs</strong> launched
<ul>
<li class="fragment"><code>response_format: {"type": "json_object", ...}</code></li>
<li class="fragment">100% reliability that output matches the your schema</li>
</ul></li>
</ul>
</section>
<section id="how-structured-outputs-work" class="slide level2">
<h2>How Structured Outputs Work</h2>
<ul>
<li class="fragment">Constrained Decoding
<ul>
<li class="fragment">When generating responses, the model normally samples from all possible next tokens</li>
<li class="fragment">With <strong>constrained decoding</strong>, the next token is <strong>dynamically filtered</strong> to only allow tokens that keep the output schema valid
<ul>
<li class="fragment">e.g., if schema requires an integer, string tokens are masked out from the probably distribution</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="how-structured-outputs-work-1" class="slide level2">
<h2>How Structured Outputs Work</h2>
<ul>
<li class="fragment">Slightly slower token generation due to computational overhead</li>
<li class="fragment">Technically, mathematically impossible to generate invalid output
<ul>
<li class="fragment">(Real world: I see 7000:1 error rates with GPT-5.1 chat)</li>
</ul></li>
</ul>
</section>
<section id="implementing-structured-outputs" class="slide level2">
<h2>Implementing Structured Outputs</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/02/notebooks/structured-outputs.ipynb" data-notebook-title="Structured Outputs" data-notebook-cellid="model">
<div id="model" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel</span>
<span id="cb21-2"><a></a></span>
<span id="cb21-3"><a></a><span class="co"># Define the model for a geographic location</span></span>
<span id="cb21-4"><a></a><span class="kw">class</span> Location(BaseModel):</span>
<span id="cb21-5"><a></a>  name: <span class="bu">str</span></span>
<span id="cb21-6"><a></a>  country: <span class="bu">str</span></span>
<span id="cb21-7"><a></a>  latitude: <span class="bu">float</span></span>
<span id="cb21-8"><a></a>  longitude: <span class="bu">float</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</section>
<section id="implementing-structured-outputs-1" class="slide level2">
<h2>Implementing Structured Outputs</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/02/notebooks/structured-outputs.ipynb" data-notebook-title="Structured Outputs" data-notebook-cellid="request">
<div id="request" class="cell" data-execution_count="13">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a></a>MODEL <span class="op">=</span> <span class="st">'openai/gpt-5.2-chat'</span> <span class="co">#@param ["openai/gpt-5.2-chat", "anthropic/claude-sonnet-4.5", "google/gemini-2.5-pro"]</span></span>
<span id="cb22-2"><a></a></span>
<span id="cb22-3"><a></a>response <span class="op">=</span> client.chat.completions.parse(</span>
<span id="cb22-4"><a></a>    model<span class="op">=</span>MODEL,</span>
<span id="cb22-5"><a></a>    messages<span class="op">=</span>[</span>
<span id="cb22-6"><a></a>        {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: <span class="st">"What are the GPS coordinates for Paris?"</span>},</span>
<span id="cb22-7"><a></a>    ],</span>
<span id="cb22-8"><a></a>    response_format<span class="op">=</span>Location</span>
<span id="cb22-9"><a></a>)</span>
<span id="cb22-10"><a></a></span>
<span id="cb22-11"><a></a>completion <span class="op">=</span> response.choices[<span class="dv">0</span>].message</span>
<span id="cb22-12"><a></a><span class="bu">print</span>(completion)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>ParsedChatCompletionMessage[Location](content='{"name":"Paris","country":"France","latitude":48.8566,"longitude":2.3522}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, parsed=Location(name='Paris', country='France', latitude=48.8566, longitude=2.3522), reasoning=None)</code></pre>
</div>
</div>
</div>
</section>
<section id="implementing-structured-outputs-2" class="slide level2">
<h2>Implementing Structured Outputs</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/02/notebooks/structured-outputs.ipynb" data-notebook-title="Structured Outputs" data-notebook-cellid="display">
<div id="display" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a></a><span class="co"># Display the JSON repesentation</span></span>
<span id="cb24-2"><a></a><span class="bu">print</span>(completion.content)</span>
<span id="cb24-3"><a></a></span>
<span id="cb24-4"><a></a><span class="co"># Display the parsed type</span></span>
<span id="cb24-5"><a></a><span class="bu">print</span>(completion.parsed)</span>
<span id="cb24-6"><a></a></span>
<span id="cb24-7"><a></a><span class="co"># Pretty-print</span></span>
<span id="cb24-8"><a></a><span class="cf">if</span> completion.parsed:</span>
<span id="cb24-9"><a></a>  location: Location <span class="op">=</span> completion.parsed</span>
<span id="cb24-10"><a></a>  <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>location<span class="sc">.</span>name<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>location<span class="sc">.</span>country<span class="sc">}</span><span class="ss"> has GPS coordinates of </span><span class="sc">{</span>location<span class="sc">.</span>latitude<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>location<span class="sc">.</span>longitude<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>{"name":"Paris","country":"France","latitude":48.8566,"longitude":2.3522}
name='Paris' country='France' latitude=48.8566 longitude=2.3522
Paris, France has GPS coordinates of 48.8566, 2.3522</code></pre>
</div>
</div>
</div>
</section></section>
<section id="demo-2" class="title-slide slide level1 center">
<h1>Demo</h1>
<p>Token Streaming and Structured Outputs</p>
</section>

<section id="hands-on-2" class="title-slide slide level1 center">
<h1>Hands-On</h1>
<p>Investigate token-streaming.ipynb and structured-outputs.ipynb. Try adding an additional field to the Location model.</p>
</section>

<section>
<section id="creating-a-chat-ui" class="title-slide slide level1 center">
<h1>Creating a Chat UI</h1>

</section>
<section id="creating-a-chat-ui-1" class="slide level2">
<h2>Creating a Chat UI</h2>
<ul>
<li class="fragment">Up to now, we’ve been making requests and printing the responses</li>
<li class="fragment">Good for learning concepts, but not a “product” that others can use</li>
<li class="fragment">We want to build a UI that supports conversation threads, streaming, rich inputs/outputs, etc.</li>
<li class="fragment">But we don’t want to start from scratch!</li>
</ul>
</section>
<section id="introducing-gradio" class="slide level2">
<h2>Introducing Gradio</h2>

<img data-src="images/gradio-website.png" class="r-stretch quarto-figure-center"><p class="caption">Source: https://www.gradio.app/</p></section>
<section id="what-is-gradio" class="slide level2">
<h2>What is Gradio?</h2>
<ul>
<li class="fragment"><strong>Created in 2019:</strong> Startup called Gradio developing demos for research/academia</li>
<li class="fragment"><strong>Acquired by Hugging Face in 2021:</strong> became the standard interface for Hugging Face Spaces</li>
<li class="fragment"><strong>Now industry standard:</strong> For ML demos - used by researchers, startups to showcase models without front-end expertise</li>
</ul>
</section>
<section id="what-is-gradio-1" class="slide level2">
<h2>What is Gradio?</h2>
<ul>
<li class="fragment">Rapid UI creation with minimal code
<ul>
<li class="fragment">5-10 lines of Python for an interactive interface. No HTML, CSS, JS required.</li>
</ul></li>
<li class="fragment">Rich input/output types
<ul>
<li class="fragment">Text, images, audio, video, files, dataframes, etc.</li>
</ul></li>
<li class="fragment">ML workflows
<ul>
<li class="fragment">Supports streaming, queue management (for server-side deployment), flagging/feedback collection</li>
</ul></li>
<li class="fragment">Deployment flexibility
<ul>
<li class="fragment">Can run locally, create temporary public links, or embed in production apps</li>
</ul></li>
</ul>
</section>
<section id="example-1-basic-interface" class="slide level2">
<h2>Example 1: Basic Interface</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/02/notebooks/gradio.ipynb" data-notebook-title="Gradio with OpenAI API (via OpenRouter)" data-notebook-cellid="example-1">
<div id="example-1" class="cell" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a></a><span class="co"># @title Example 1: Basic Gradio interface</span></span>
<span id="cb26-2"><a></a></span>
<span id="cb26-3"><a></a><span class="im">import</span> gradio <span class="im">as</span> gr</span>
<span id="cb26-4"><a></a></span>
<span id="cb26-5"><a></a><span class="kw">def</span> image_classifier(inp):</span>
<span id="cb26-6"><a></a>    <span class="cf">return</span> {<span class="st">'cat'</span>: <span class="fl">0.3</span>, <span class="st">'dog'</span>: <span class="fl">0.7</span>}</span>
<span id="cb26-7"><a></a></span>
<span id="cb26-8"><a></a>demo <span class="op">=</span> gr.Interface(fn<span class="op">=</span>image_classifier, inputs<span class="op">=</span><span class="st">"image"</span>, outputs<span class="op">=</span><span class="st">"label"</span>)</span>
<span id="cb26-9"><a></a>demo.launch()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</section>
<section id="example-1-basic-interface-1" class="slide level2">
<h2>Example 1: Basic Interface</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/02/notebooks/gradio.ipynb" data-notebook-title="Gradio with OpenAI API (via OpenRouter)" data-notebook-cellid="example-1">
<div id="example-1" class="cell" data-execution_count="17">
<div class="cell-output cell-output-stdout">
<pre><code>* Running on local URL:  http://127.0.0.1:7870
* To create a public link, set `share=True` in `launch()`.</code></pre>
</div>
<div class="cell-output cell-output-display">
<div><iframe src="http://127.0.0.1:7870/" width="100%" height="500" allow="autoplay; camera; microphone; clipboard-read; clipboard-write;" frameborder="0" allowfullscreen=""></iframe></div>
</div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code></code></pre>
</div>
</div>
</div>
</section>
<section id="example-2-basic-chat-interface" class="slide level2">
<h2>Example 2: Basic Chat Interface</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/02/notebooks/gradio.ipynb" data-notebook-title="Gradio with OpenAI API (via OpenRouter)" data-notebook-cellid="example-2">
<div id="example-2" class="cell" data-execution_count="18">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a></a><span class="co"># @title Example 2: Basic chat interface with conversation history</span></span>
<span id="cb29-2"><a></a></span>
<span id="cb29-3"><a></a><span class="im">import</span> gradio <span class="im">as</span> gr</span>
<span id="cb29-4"><a></a></span>
<span id="cb29-5"><a></a><span class="kw">def</span> chat_with_history(message, history):</span>
<span id="cb29-6"><a></a>    <span class="co"># Add current message</span></span>
<span id="cb29-7"><a></a>    messages <span class="op">=</span> history <span class="op">+</span> [{<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: message}]</span>
<span id="cb29-8"><a></a>    </span>
<span id="cb29-9"><a></a>    <span class="co"># Get response from API</span></span>
<span id="cb29-10"><a></a>    response <span class="op">=</span> client.chat.completions.create(</span>
<span id="cb29-11"><a></a>        model<span class="op">=</span><span class="st">'openai/gpt-5.2-chat'</span>,</span>
<span id="cb29-12"><a></a>        messages<span class="op">=</span>messages,</span>
<span id="cb29-13"><a></a>    )</span>
<span id="cb29-14"><a></a>    </span>
<span id="cb29-15"><a></a>    <span class="cf">return</span> response.choices[<span class="dv">0</span>].message.content</span>
<span id="cb29-16"><a></a></span>
<span id="cb29-17"><a></a><span class="co"># Create a chat interface</span></span>
<span id="cb29-18"><a></a>demo <span class="op">=</span> gr.ChatInterface(</span>
<span id="cb29-19"><a></a>    fn<span class="op">=</span>chat_with_history,</span>
<span id="cb29-20"><a></a>    title<span class="op">=</span><span class="st">"Basic Chat with Conversation History"</span></span>
<span id="cb29-21"><a></a>)</span>
<span id="cb29-22"><a></a></span>
<span id="cb29-23"><a></a>demo.launch()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</section>
<section id="example-2-basic-chat-interface-1" class="slide level2">
<h2>Example 2: Basic Chat Interface</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/02/notebooks/gradio.ipynb" data-notebook-title="Gradio with OpenAI API (via OpenRouter)" data-notebook-cellid="example-2">
<div id="example-2" class="cell" data-execution_count="18">
<div class="cell-output cell-output-stdout">
<pre><code>* Running on local URL:  http://127.0.0.1:7871
* To create a public link, set `share=True` in `launch()`.</code></pre>
</div>
<div class="cell-output cell-output-display">
<div><iframe src="http://127.0.0.1:7871/" width="100%" height="500" allow="autoplay; camera; microphone; clipboard-read; clipboard-write;" frameborder="0" allowfullscreen=""></iframe></div>
</div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code></code></pre>
</div>
</div>
</div>
</section>
<section id="example-3-streaming-chat-interface" class="slide level2">
<h2>Example 3: Streaming Chat Interface</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/02/notebooks/gradio.ipynb" data-notebook-title="Gradio with OpenAI API (via OpenRouter)" data-notebook-cellid="example-3">
<div id="example-3" class="cell" data-execution_count="19">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb32"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a></a><span class="co"># @title Example 3: Streaming chat interface</span></span>
<span id="cb32-2"><a></a></span>
<span id="cb32-3"><a></a><span class="kw">def</span> chat_with_streaming(message, history):</span>
<span id="cb32-4"><a></a>    messages <span class="op">=</span> history <span class="op">+</span> [{<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: message}]</span>
<span id="cb32-5"><a></a>    </span>
<span id="cb32-6"><a></a>    <span class="co"># Stream the response</span></span>
<span id="cb32-7"><a></a>    stream <span class="op">=</span> client.chat.completions.create(</span>
<span id="cb32-8"><a></a>        model<span class="op">=</span><span class="st">'openai/gpt-5.2-chat'</span>,</span>
<span id="cb32-9"><a></a>        messages<span class="op">=</span>messages,</span>
<span id="cb32-10"><a></a>        stream<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb32-11"><a></a>    )</span>
<span id="cb32-12"><a></a>    </span>
<span id="cb32-13"><a></a>    response_text <span class="op">=</span> <span class="st">""</span></span>
<span id="cb32-14"><a></a>    <span class="cf">for</span> chunk <span class="kw">in</span> stream:</span>
<span id="cb32-15"><a></a>        <span class="cf">if</span> chunk.choices[<span class="dv">0</span>].delta.content <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb32-16"><a></a>            token <span class="op">=</span> chunk.choices[<span class="dv">0</span>].delta.content</span>
<span id="cb32-17"><a></a>            response_text <span class="op">+=</span> token</span>
<span id="cb32-18"><a></a>            <span class="cf">yield</span> response_text</span>
<span id="cb32-19"><a></a></span>
<span id="cb32-20"><a></a><span class="co"># Create streaming chat interface</span></span>
<span id="cb32-21"><a></a>demo <span class="op">=</span> gr.ChatInterface(</span>
<span id="cb32-22"><a></a>    fn<span class="op">=</span>chat_with_streaming,</span>
<span id="cb32-23"><a></a>    title<span class="op">=</span><span class="st">"AI Chat with Streaming"</span>,</span>
<span id="cb32-24"><a></a>)</span>
<span id="cb32-25"><a></a></span>
<span id="cb32-26"><a></a>demo.launch()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</section>
<section id="example-2-streaming-chat-interface" class="slide level2">
<h2>Example 2: Streaming Chat Interface</h2>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/CS-394/CS-394/src/02/notebooks/gradio.ipynb" data-notebook-title="Gradio with OpenAI API (via OpenRouter)" data-notebook-cellid="example-3">
<div id="example-3" class="cell" data-execution_count="19">
<div class="cell-output cell-output-stdout">
<pre><code>* Running on local URL:  http://127.0.0.1:7872
* To create a public link, set `share=True` in `launch()`.</code></pre>
</div>
<div class="cell-output cell-output-display">
<div><iframe src="http://127.0.0.1:7872/" width="100%" height="500" allow="autoplay; camera; microphone; clipboard-read; clipboard-write;" frameborder="0" allowfullscreen=""></iframe></div>
</div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code></code></pre>
</div>
</div>
</div>
</section></section>
<section id="demo-3" class="title-slide slide level1 center">
<h1>Demo</h1>
<p>Gradio Notebook</p>
</section>

<section id="hands-on-3" class="title-slide slide level1 center">
<h1>Hands-On</h1>
<p>Explore the three examples in gradio.ipynb.</p>
</section>

<section>
<section id="looking-ahead-to-next-week" class="title-slide slide level1 center">
<h1>Looking Ahead to Next Week</h1>

</section>
<section id="looking-ahead-to-next-week-1" class="slide level2">
<h2>Looking Ahead to Next Week</h2>
<ul>
<li class="fragment"><a href="https://simonguest.github.io/CS-394/src/02/assignment.html" class="external" target="_blank">This week’s assignment!</a></li>
<li class="fragment">Explore the world of AI Agents</li>
<li class="fragment">Create agents, building upon our knowledge of Gradio</li>
<li class="fragment">Give the agent tools to perform functions beyond what an LLM can do</li>
</ul>
</section></section>
<section>
<section id="references" class="title-slide slide level1 center">
<h1>References</h1>

</section>
<section id="references-1" class="slide level2">
<h2>References</h2>


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="../../theme/logos/DigiPen_RGB_Red.png" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.15,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/simonguest\.github\.io\/CS-394\/");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>