{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81cbf5c3",
   "metadata": {},
   "source": [
    "# Using llama.cpp Binding for Python\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/simonguest/CS-394/blob/main/src/05/notebooks/python-binding.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "<a target=\"_blank\" href=\"https://github.com/simonguest/CS-394/raw/refs/heads/main/src/05/notebooks/python-binding.ipynb\">\n",
    "  <img src=\"https://img.shields.io/badge/Download_.ipynb-blue\" alt=\"Download .ipynb\"/>\n",
    "</a>\n",
    "\n",
    "**Note**: Before running this notebook, you should follow [README.md](../code/README.md) to first download the GGUF model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffdc126",
   "metadata": {},
   "source": [
    "## Install the llama-cpp-python binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14bb8487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.13.1 environment at: /Users/simon/Dev/CS-394/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m6 packages\u001b[0m \u001b[2min 110ms\u001b[0m\u001b[0m                                         \u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 4ms\u001b[0m\u001b[0m3.16                             \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdiskcache\u001b[0m\u001b[2m==5.6.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mllama-cpp-python\u001b[0m\u001b[2m==0.3.16\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cb7c15",
   "metadata": {},
   "source": [
    "## Load the local gguf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "GGUF_MODEL = f\"../code/gguf/gemma-3-1b-it-Q4_K_M.gguf\"\n",
    "\n",
    "llm = Llama(\n",
    "      model_path=GGUF_MODEL,\n",
    "      chat_format=\"gemma\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e8a273",
   "metadata": {},
   "source": [
    "## Chat with the model using chat completion API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "chat",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     205.62 ms\n",
      "llama_perf_context_print: prompt eval time =     205.11 ms /    10 tokens (   20.51 ms per token,    48.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =     394.64 ms /    32 runs   (   12.33 ms per token,    81.09 tokens per second)\n",
      "llama_perf_context_print:       total time =     611.16 ms /    42 tokens\n",
      "llama_perf_context_print:    graphs reused =         30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-2887bb2b-b1a5-428d-a42b-46c83a97fb6b',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1770147671,\n",
       " 'model': '../code/gguf/gemma-3-1b-it-Q4_K_M.gguf',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': \"Hello there! How's your day going so far? ðŸ˜Š \\n\\nIs there anything you'd like to chat about, or need any help with?\"},\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 10, 'completion_tokens': 32, 'total_tokens': 42}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.create_chat_completion(\n",
    "      messages = [\n",
    "          {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": \"Hello\"\n",
    "          }\n",
    "      ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
