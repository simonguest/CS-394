{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b2ebb72",
   "metadata": {},
   "source": [
    "# Translation Transformer\n",
    "\n",
    "In this notebook, we use a small transformer (Helsinki-NLP/opus-mt-fr-en) to translate from French to English.\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/simonguest/CS-394/blob/main/src/01/notebooks/translation-transformer.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "<a target=\"_blank\" href=\"https://github.com/simonguest/CS-394/raw/refs/heads/main/src/01/notebooks/translation-transformer.ipynb\">\n",
    "  <img src=\"https://img.shields.io/badge/Download_.ipynb-blue\" alt=\"Download .ipynb\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deaee52",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-model",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554eae15412f407392def18a94e2cdf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980e33c84ae642ee80074c3d4d7f19d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a1afb6c66a4bdb9618b8d7fbebc31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simon/Dev/CS-394/.venv/lib/python3.13/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "247f590ae2df430782f38916467e2989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c46def7aa704024a5d1c6d1fef58711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-fr-en\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a1b892",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tokenize",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8703,    2, 1027, 5682,   21,  682,   54,    0])\n",
      "Tokens: ['▁Bonjour', ',', '▁comment', '▁allez', '-', 'vous', '?', '</s>']\n"
     ]
    }
   ],
   "source": [
    "french_text = \"Bonjour, comment allez-vous?\"\n",
    "input_ids = tokenizer.encode(french_text, return_tensors=\"pt\")\n",
    "print(input_ids[0])\n",
    "print(\"Tokens:\", tokenizer.convert_ids_to_tokens(input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e89f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: torch.Size([1, 8, 512])\n",
      "Encoder output: BaseModelOutput(last_hidden_state=tensor([[[-0.3943,  0.4660,  0.0190,  ..., -0.5069,  0.2120, -0.3190],\n",
      "         [ 0.0957,  0.0780,  0.1918,  ..., -0.0854,  0.2138,  0.1528],\n",
      "         [-0.6160,  0.0295,  0.1918,  ..., -0.3886,  0.0770,  0.2311],\n",
      "         ...,\n",
      "         [-0.1839, -0.3798,  0.1832,  ..., -0.0041, -0.3633, -0.5455],\n",
      "         [ 0.0153,  0.0264,  0.1122,  ...,  0.1966, -0.3027, -0.3659],\n",
      "         [-0.0484,  0.0147,  0.0078,  ..., -0.1359, -0.0295, -0.0799]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "# @title Demonstrate contextual vectors using the encoder\n",
    "\n",
    "# French: \"Bonjour , comment allez  - vous  ?\"\n",
    "#          ↓       ↓    ↓      ↓    ↓  ↓    ↓\n",
    "# Encoder: [v1]   [v2] [v3]  [v4] [v5][v6][v7]  ← 7 vectors, each 512-dim\n",
    "#          └─────────────────────────────────┘\n",
    "\n",
    "encoder = model.get_encoder()\n",
    "encoder_output = encoder(input_ids)\n",
    "print(\"Encoder output shape:\", encoder_output.last_hidden_state.shape)\n",
    "print(\"Encoder output:\", encoder_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532519ba",
   "metadata": {},
   "source": [
    "## Run through tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transformer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[59513, 10537,     2,   541,    52,    55,    54,     0]])\n"
     ]
    }
   ],
   "source": [
    "output_ids = model.generate(input_ids)\n",
    "print(output_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beaa43e",
   "metadata": {},
   "source": [
    "## Decode back to tokens to complete the translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decode",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: Hello, how are you?\n"
     ]
    }
   ],
   "source": [
    "english_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "print(\"Translation:\", english_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
