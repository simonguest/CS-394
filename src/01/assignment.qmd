---
title: "Week 1 Assignment - Experiment with Text Continuation Styles"
format: html
execute:
  enabled: false
---
**Objective:** Create a Colab notebook that uses GPT-2 to generate creative text continuations with different styles.

**Requirements:**

- Load a pre-trained GPT-2 model (using HuggingFace transformers - same approach as used in GPT-2.ipynb)
- Create 3 different story starters in different genres/styles. For example:
  - Fantasy/Adventure: "In a land of dragons and magic..."
  - Sci-fi: "The year is 2157. Humanity has just..."
  - Mystery: "The detective examined the crime scene and noticed..."
  - (or choose your own three)
- Then adjust for:
  - Greedy decoding vs. sampling
  - Different temperature values
  - How the opening sentence shapes the continuation (e.g., short vs. long)
- Document your observations (using Markdown in the notebook)
  - What differences do you notice between the strategies?
  - What worked well (or surprised you!)
  - What didn't work that well

**Deliverable: A Colab/Jupyter notebook with:**

- Code cells with your implementation
- Outputs of generated text from GPT-2
- Markdown cells explaining what each sampling strategy does and any observations

**Hint:**

For better results, use a larger GPT-2 model on Colab T4.

```{python}
tokenizer = GPT2Tokenizer.from_pretrained("gpt2-medium")
model = GPT2LMHeadModel.from_pretrained("gpt2-medium")
```