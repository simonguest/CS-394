---
title: "Module 2 Assignment: Gradio Travel Planner"
format: html
execute:
  enabled: false
---
**Objective:** Build a chat interface (in a separate Colab notebook) that helps a user complete tasks.

**Requirements:**

- Gradio chat interface with streaming responses
- System prompt that defines the AI as a travel planning expert (or pick your own scenario, if you have a better idea!)
- Implements a well-thought out system prompt (with feedback on the rationale behind it).
- Demonstrates at least 2 different models via OpenRouter as a dropdown in Gradio. (Not necessarily at the same time.)
  - Try to pick models of different sizes to compare the differences. If you search for free models (https://openrouter.ai/models?q=free) you can also avoid incurring any costs.
- Use structured outputs when returning results to the user (e.g., a downloadable itinerary that the user can download)
  - Example schema: Trip with fields like destination, duration_days, activities (list), budget_level, daily_schedule (list of day objects)

**Deliverable: A Colab/Jupyter notebook with:**

- Code cells with your implementation
- Uses OPENROUTER_API_KEY for the API token. (Please do not include your API key in your notebook!)
- Markdown cells explaining what the notebook does and any observations

**Hint**

- To get streaming and structured outputs working in Gradio, you may want to think of this as two calls to the model:
  - The first call asks the model to think about the problem (e.g., "How can you help the user solve their travel question?") You can use streaming to display the response token-by-token in Gradio.
  - The second call then takes the model's prior answer and creates a new call (e.g., "From your thinking, create an itinerary.") You can then use structured outputs to ensure that this matches the schema, and map that to a component in the Gradio UI (gr.JSON is fine to display this, unless you want to get more creative :).